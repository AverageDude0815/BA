{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "def train_model(model, dataset, validation_set, learning_rate, batch_size, epochs): \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) #ToDo: lr scheduler instead of lr fix\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    # Train linear model using SGD on mini-batches.\n",
    "    for epoch in range(epochs):\n",
    "        # DataLoader generates random batches from a given dataset.\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_data_loader = data.DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "         # We want to report the training loss after each epoch\n",
    "        epoch_loss = 0.0 \n",
    "\n",
    "        for batch in data_loader:\n",
    "            # After each iteration of the training step, reset the local gradients stored in the network to zero.\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Compute the forward pass.\n",
    "            # Numpy uses doubles by default but Torch expects floats, since the added accuracy of doubles \n",
    "            # is generally not useful for neural networks.\n",
    "            # We fix this issue by changing the datatype of 'X' and 'y' with the .float method.\n",
    "            yhat = model.forward(batch['X'].float())\n",
    "\n",
    "            # Compute the batch error.\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long())\n",
    "            epoch_loss += batch_loss.item()\n",
    "            \n",
    "            # Backpropagate the gradient and adjust the weights.\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Epoch ended, save values for later plotting and print information\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for batch in val_data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float())\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long())\n",
    "            validation_loss += batch_loss.item()\n",
    "        validation_losses.append(validation_loss)\n",
    "        \n",
    "    return epoch_losses, validation_losses\n",
    "            \n",
    "\n",
    "\n",
    "#Some methods for evaluating results\n",
    "def get_confusion_matrix(y_pred, y_true, n_classes):\n",
    "    assert len(y_pred) == len(y_true)\n",
    "    results = np.zeros(shape=(n_classes, n_classes))\n",
    "    for i in range(len(y_pred)):\n",
    "        results[y_pred[i], y_true[i]] += 1\n",
    "    return results\n",
    "    \n",
    "def precision(y_pred, y_true, n_classes):\n",
    "    precision = np.zeros(shape=n_classes)\n",
    "    confusion_matrix = get_confusion_matrix(y_pred, y_true, n_classes)\n",
    "    for i in range(n_classes):\n",
    "        sum_of_row = confusion_matrix[i].sum()\n",
    "        if confusion_matrix[i, i] != 0:\n",
    "            precision[i] = confusion_matrix[i, i] / sum_of_row\n",
    "    return precision\n",
    "\n",
    "def recall(y_pred, y_true, n_classes):\n",
    "    recall = np.zeros(shape=n_classes)\n",
    "    confusion_matrix = get_confusion_matrix(y_pred, y_true, n_classes)\n",
    "    for i in range(n_classes):\n",
    "        sum_of_column = confusion_matrix[:,i].sum()\n",
    "        if confusion_matrix[i, i] != 0:\n",
    "            recall[i] = confusion_matrix[i, i] / sum_of_column\n",
    "    return recall\n",
    "\n",
    "def f1score(y_pred, y_true, n_classes):\n",
    "    p = precision(y_pred, y_true, n_classes)\n",
    "    r = recall(y_pred, y_true, n_classes)\n",
    "    f1 = np.zeros(shape=n_classes)\n",
    "    for i in range(n_classes):\n",
    "        if r[i] + p[i] != 0:\n",
    "            f1[i] = 2 * p[i] * r[i] / (r[i] + p[i])\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "n_classes = 10\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "print(mnist_trainset)\n",
    "print(mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([60000, 3, 28, 28])\n",
      "X_test: torch.Size([10000, 3, 28, 28])\n",
      "y_train: torch.Size([60000])\n",
      "y_test: torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    helper = torch.unsqueeze(x_grey, 1)\n",
    "    return helper.repeat(1, 3, 1, 1).float()\n",
    "\n",
    "X_train_grey = mnist_trainset.train_data\n",
    "X_train = to_rgb(X_train_grey)\n",
    "X_test_grey = mnist_testset.test_data\n",
    "X_test = to_rgb(X_test_grey)\n",
    "y_train = mnist_trainset.train_labels\n",
    "y_test = mnist_testset.test_labels\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=False) # set model here\n",
    "in_ftr = model.fc.in_features\n",
    "out_ftr = n_classes\n",
    "model.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "    \n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check specs for GPU-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device name: NVIDIA GeForce 940MX\n",
      "cuda device id 0\n"
     ]
    }
   ],
   "source": [
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('cuda device name:', torch.cuda.get_device_name())\n",
    "print('cuda device id', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model and data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train.to(device)\n",
    "print('worked?', X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, validation_set, base_lr=0.01, max_lr=0.01, batch_size=64, epochs=1, \n",
    "                f_opt=optim.SGD, f_loss=F.cross_entropy):\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=base_lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr)\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_data_loader = data.DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        \n",
    "        epoch_loss = 0.0 \n",
    "        for batch in data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for batch in val_data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            validation_loss += batch_loss.item()\n",
    "        validation_losses.append(validation_loss)\n",
    "        \n",
    "    return epoch_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 144.5266956485575\n"
     ]
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "max_lr = 0.1\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "f_opt=optim.SGD\n",
    "f_loss=F.cross_entropy\n",
    "\n",
    "training_loss, validation_loss = train_model(model.to(device), dataset_train, dataset_test,\n",
    "                                             base_lr, max_lr, batch_size, epochs,\n",
    "                                             f_opt, f_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x217a2e4b5e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(training_loss) * batch_size / len(X_train), label='training loss')\n",
    "plt.plot(np.array(validation_loss) * batch_size / len(X_test), label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: #avoid automatic loading and overriding of existing data when executing in Google Colab\n",
    "    import csv\n",
    "    from google.colab import files\n",
    "    with open('train_loss', 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(training_loss)\n",
    "\n",
    "    with open('val_loss', 'w') as f: \n",
    "        write = csv.writer(f)  \n",
    "        write.writerow(validation_loss)\n",
    "\n",
    "    files.download('train_loss')\n",
    "    files.download('val_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
