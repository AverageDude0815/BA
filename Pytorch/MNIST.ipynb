{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "def train_model(model, dataset, validation_set, learning_rate, batch_size, epochs): \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) #ToDo: lr scheduler instead of lr fix\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    # Train linear model using SGD on mini-batches.\n",
    "    for epoch in range(epochs):\n",
    "        # DataLoader generates random batches from a given dataset.\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_data_loader = data.DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "         # We want to report the training loss after each epoch\n",
    "        epoch_loss = 0.0 \n",
    "\n",
    "        for batch in data_loader:\n",
    "            # After each iteration of the training step, reset the local gradients stored in the network to zero.\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Compute the forward pass.\n",
    "            # Numpy uses doubles by default but Torch expects floats, since the added accuracy of doubles \n",
    "            # is generally not useful for neural networks.\n",
    "            # We fix this issue by changing the datatype of 'X' and 'y' with the .float method.\n",
    "            yhat = model.forward(batch['X'].float())\n",
    "\n",
    "            # Compute the batch error.\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long())\n",
    "            epoch_loss += batch_loss.item()\n",
    "            \n",
    "            # Backpropagate the gradient and adjust the weights.\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Epoch ended, save values for later plotting and print information\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for batch in val_data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float())\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long())\n",
    "            validation_loss += batch_loss.item()\n",
    "        validation_losses.append(validation_loss)\n",
    "        \n",
    "    return epoch_losses, validation_losses\n",
    "            \n",
    "\n",
    "\n",
    "#Some methods for evaluating results\n",
    "def get_confusion_matrix(y_pred, y_true, n_classes):\n",
    "    assert len(y_pred) == len(y_true)\n",
    "    results = np.zeros(shape=(n_classes, n_classes))\n",
    "    for i in range(len(y_pred)):\n",
    "        results[y_pred[i], y_true[i]] += 1\n",
    "    return results\n",
    "    \n",
    "def precision(y_pred, y_true, n_classes):\n",
    "    precision = np.zeros(shape=n_classes)\n",
    "    confusion_matrix = get_confusion_matrix(y_pred, y_true, n_classes)\n",
    "    for i in range(n_classes):\n",
    "        sum_of_row = confusion_matrix[i].sum()\n",
    "        if confusion_matrix[i, i] != 0:\n",
    "            precision[i] = confusion_matrix[i, i] / sum_of_row\n",
    "    return precision\n",
    "\n",
    "def recall(y_pred, y_true, n_classes):\n",
    "    recall = np.zeros(shape=n_classes)\n",
    "    confusion_matrix = get_confusion_matrix(y_pred, y_true, n_classes)\n",
    "    for i in range(n_classes):\n",
    "        sum_of_column = confusion_matrix[:,i].sum()\n",
    "        if confusion_matrix[i, i] != 0:\n",
    "            recall[i] = confusion_matrix[i, i] / sum_of_column\n",
    "    return recall\n",
    "\n",
    "def f1score(y_pred, y_true, n_classes):\n",
    "    p = precision(y_pred, y_true, n_classes)\n",
    "    r = recall(y_pred, y_true, n_classes)\n",
    "    f1 = np.zeros(shape=n_classes)\n",
    "    for i in range(n_classes):\n",
    "        if r[i] + p[i] != 0:\n",
    "            f1[i] = 2 * p[i] * r[i] / (r[i] + p[i])\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "print(mnist_trainset)\n",
    "print(mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([60000, 3, 28, 28])\n",
      "X_test: torch.Size([10000, 3, 28, 28])\n",
      "y_train: torch.Size([60000])\n",
      "y_test: torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\robin\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    helper = torch.unsqueeze(x_grey, 1)\n",
    "    return helper.repeat(1, 3, 1, 1).float()\n",
    "\n",
    "X_train_grey = mnist_trainset.train_data\n",
    "X_train = to_rgb(X_train_grey)\n",
    "X_test_grey = mnist_testset.test_data\n",
    "X_test = to_rgb(X_test_grey)\n",
    "y_train = mnist_trainset.train_labels\n",
    "y_test = mnist_testset.test_labels\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "epochs = 2\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "debugg = False\n",
    "\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "in_ftr = resnet.fc.in_features\n",
    "out_ftr = n_classes\n",
    "resnet.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "if debugg:\n",
    "    yhat = resnet.forward(X_test)\n",
    "    print(yhat.shape)\n",
    "    \n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)\n",
    "#training_loss, validation_loss = train_model(resnet, dataset_train, dataset_test, learning_rate, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(np.array(training_loss) * 64 / len(X_train), label='training loss')\n",
    "#plt.plot(np.array(validation_loss) * 64 / len(X_test), label='validation loss')\n",
    "#plt.xlabel('Epochs')\n",
    "#plt.ylabel('Mean Cross Entropy Loss')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce 940MX\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X_train.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "X_train.to(device)\n",
    "print(X_train.is_cuda)\n",
    "print(X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_gpu(model, dataset, validation_set, learning_rate, batch_size, epochs): \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) #ToDo: lr scheduler instead of lr fix\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    # Train linear model using SGD on mini-batches.\n",
    "    for epoch in range(epochs):\n",
    "        # DataLoader generates random batches from a given dataset.\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_data_loader = data.DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "         # We want to report the training loss after each epoch\n",
    "        epoch_loss = 0.0 \n",
    "\n",
    "        for batch in data_loader:\n",
    "            # After each iteration of the training step, reset the local gradients stored in the network to zero.\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Compute the forward pass.\n",
    "            # Numpy uses doubles by default but Torch expects floats, since the added accuracy of doubles \n",
    "            # is generally not useful for neural networks.\n",
    "            # We fix this issue by changing the datatype of 'X' and 'y' with the .float method.\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "\n",
    "            # Compute the batch error.\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item()\n",
    "            \n",
    "            # Backpropagate the gradient and adjust the weights.\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Epoch ended, save values for later plotting and print information\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for batch in val_data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            validation_loss += batch_loss.item()\n",
    "        validation_losses.append(validation_loss)\n",
    "        \n",
    "    return epoch_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_loss, validation_loss = train_model_gpu(resnet.to(device), dataset_train, dataset_test,\n",
    "                                             #learning_rate, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_clr_gpu(model, dataset, validation_set, base_lr, max_lr, batch_size, epochs): \n",
    "    optimizer = optim.SGD(model.parameters(), lr=base_lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr)\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_data_loader = data.DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0 \n",
    "\n",
    "        for batch in data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss} - LR: {scheduler.get_last_lr()}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for batch in val_data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            validation_loss += batch_loss.item()\n",
    "        validation_losses.append(validation_loss)\n",
    "        \n",
    "    return epoch_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Loss: 85.43215179257095 - LR: [0.036999999999999984]\n",
      "Epoch 2/2 - Loss: 38.633004629286006 - LR: [0.06400000000000002]\n"
     ]
    }
   ],
   "source": [
    "training_loss, validation_loss = train_model_clr_gpu(resnet.to(device), dataset_train, dataset_test,\n",
    "                                                     base_lr=0.01, max_lr=0.1, batch_size=batch_size, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17e5cf95250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(training_loss) * 64 / len(X_train), label='training loss')\n",
    "plt.plot(np.array(validation_loss) * 64 / len(X_test), label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from google.colab import files\n",
    "\n",
    "with open('train_loss', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(training_loss)\n",
    "    \n",
    "with open('val_loss', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_loss)\n",
    "\n",
    "files.download('train_loss')\n",
    "files.download('val_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
