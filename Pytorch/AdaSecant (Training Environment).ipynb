{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist = False\n",
    "cifar10 = True\n",
    "cifar100 = False\n",
    "assert mnist ^ cifar10 ^ cifar100\n",
    "\n",
    "n_classes = 10\n",
    "if mnist:\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "if cifar10:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "if cifar100:\n",
    "    n_classes = 100\n",
    "    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "print(trainset)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([50000, 3, 32, 32])\n",
      "y_train: torch.Size([50000])\n",
      "X_test: torch.Size([10000, 3, 32, 32])\n",
      "y_test: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    if len(x_grey.size()) == 3:\n",
    "        helper = torch.unsqueeze(x_grey, 1)\n",
    "        return helper.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 1:\n",
    "        return x_grey.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 3:\n",
    "        return x_grey\n",
    "    elif len(x_grey.size()) == 4:\n",
    "        raise ValueError(f'The size of this image tensor is not valid.\\\n",
    "        A 4th order image tensor must have dim1==1 (grey-scale) or dim1==3 (rgb).\\\n",
    "        Unknown format cannot be transformed to rgb.')\n",
    "    else:\n",
    "        raise ValueError(f'The size of this image-tensor is not valid.\\\n",
    "        Must be either 3rd (grey-scale) order tensor or 4th order tensor (rgb).\\\n",
    "        Got order {len(x_grey.size())}')\n",
    "        \n",
    "def swap_data(X):\n",
    "    X1 = np.swapaxes(X, 1, 3)\n",
    "    X2 = np.swapaxes(X1, 2, 3)\n",
    "    return X2\n",
    "\n",
    "if mnist:\n",
    "    X_train_grey = trainset.train_data\n",
    "    X_train = to_rgb(X_train_grey)\n",
    "    X_test_grey = testset.test_data\n",
    "    X_test = to_rgb(X_test_grey)\n",
    "    y_train = trainset.train_labels\n",
    "    y_test = testset.test_labels\n",
    "else:\n",
    "    X_train = torch.tensor(swap_data(trainset.data))\n",
    "    y_train = torch.tensor(trainset.targets)\n",
    "    X_test = torch.tensor(swap_data(testset.data))\n",
    "    y_test = torch.tensor(testset.targets)\n",
    "    \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load, modifications and GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([256, 10])\n",
      "y_train: torch.Size([256])\n",
      "X_test: torch.Size([256, 10])\n",
      "y_test: torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0036, -0.1017,  0.0205,  0.1710, -0.2985, -0.2382, -0.1095, -0.3037,\n",
      "          0.2978,  0.2353],\n",
      "        [-0.1922,  0.0030, -0.2897,  0.1280, -0.0778, -0.0530,  0.3139, -0.0782,\n",
      "         -0.2401,  0.0117],\n",
      "        [-0.2413,  0.0361, -0.1707,  0.1223, -0.1048, -0.0226,  0.3035, -0.2230,\n",
      "          0.1959, -0.2756],\n",
      "        [ 0.2316, -0.1993,  0.2605,  0.3152, -0.1407,  0.0285,  0.2101, -0.0187,\n",
      "         -0.0424,  0.2661],\n",
      "        [-0.2136, -0.0364,  0.0688, -0.2647, -0.0705, -0.2862,  0.1758,  0.2815,\n",
      "          0.0928,  0.0526],\n",
      "        [-0.2113, -0.3107, -0.0816, -0.0384,  0.2678,  0.1973,  0.2283, -0.1724,\n",
      "         -0.1101, -0.2932],\n",
      "        [-0.2576, -0.0262,  0.1465, -0.0445,  0.2611, -0.1104, -0.0842,  0.0780,\n",
      "          0.2641, -0.1770],\n",
      "        [-0.2069,  0.2309,  0.2683, -0.1383,  0.0054,  0.2565,  0.1969,  0.3017,\n",
      "          0.2544,  0.0127],\n",
      "        [ 0.1752,  0.1671, -0.0879,  0.0334, -0.0058,  0.1254,  0.0875, -0.1475,\n",
      "          0.1223, -0.2898],\n",
      "        [ 0.0420, -0.0886,  0.1202,  0.1984, -0.2045,  0.2961,  0.0732,  0.2583,\n",
      "          0.1442,  0.2152]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0718,  0.0186,  0.0725,  0.3013, -0.2274, -0.3067, -0.0312, -0.2523,\n",
      "         0.1291,  0.0698], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1595,  0.1403,  0.1499,  0.1112, -0.1117, -0.2030, -0.1277,  0.0542,\n",
      "         -0.0981,  0.3004],\n",
      "        [ 0.0733, -0.0043, -0.3056,  0.1804,  0.2009,  0.2498, -0.2512,  0.0312,\n",
      "          0.2819,  0.1822],\n",
      "        [ 0.3162,  0.2201, -0.2582,  0.0246,  0.0190,  0.0132, -0.1960, -0.2079,\n",
      "          0.1560, -0.0647],\n",
      "        [ 0.0748, -0.1023, -0.2344, -0.2507,  0.0931, -0.0392, -0.2471, -0.1494,\n",
      "         -0.2555,  0.0788],\n",
      "        [-0.0169, -0.1730,  0.1398,  0.3129, -0.3017, -0.2746, -0.0994,  0.2548,\n",
      "         -0.2018, -0.0935],\n",
      "        [ 0.2488, -0.0884, -0.0188, -0.0694,  0.0438, -0.0211, -0.3072,  0.1717,\n",
      "          0.0749,  0.1815],\n",
      "        [ 0.1121, -0.2434,  0.2954,  0.3042, -0.1179,  0.2333,  0.0004, -0.0275,\n",
      "          0.1153,  0.3043],\n",
      "        [-0.2711, -0.0486,  0.2452,  0.2767, -0.1517, -0.1744,  0.0649,  0.2725,\n",
      "          0.2341, -0.0526],\n",
      "        [-0.1021, -0.1880, -0.1320,  0.1658, -0.1603, -0.2342,  0.1142, -0.1188,\n",
      "          0.1847,  0.1519],\n",
      "        [-0.2762,  0.0732,  0.2883,  0.1027,  0.2332,  0.0189, -0.1306, -0.3082,\n",
      "          0.2951, -0.1567]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1204, -0.0077, -0.2534, -0.1414, -0.0333, -0.1445, -0.0113, -0.0869,\n",
      "        -0.0577, -0.2227], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "'''\n",
    "model = models.resnet18(pretrained=False) # set model here\n",
    "in_ftr = model.fc.in_features\n",
    "out_ftr = n_classes\n",
    "model.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "'''\n",
    "\n",
    "# redefining stuff for AdaSecant test runs\n",
    "X_train = torch.rand(256, 10)\n",
    "X_test = torch.rand(256, 10)\n",
    "y_train = torch.randint(10, (256,))\n",
    "y_test = torch.randint(10, (256,))\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "model = torch.nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10))\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check specs for GPU-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device name: NVIDIA GeForce 940MX\n",
      "cuda device id 0\n"
     ]
    }
   ],
   "source": [
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('cuda device name:', torch.cuda.get_device_name())\n",
    "print('cuda device id', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model and data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train.to(device)\n",
    "print('worked?', X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing AdaSecant\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py\n",
    "\n",
    "<ins>Indices:\n",
    "\n",
    "- $i\\in\\{1, ..., n\\}$: parameter\n",
    "\n",
    "- $k\\in\\{1, ..., m\\}$: sample in minibatch\n",
    "\n",
    "- $j\\in\\{1, ..., n_{iter}\\}$: iterations; $n_{iter} = \\lfloor\\frac{epochs}{m}\\rfloor$, if drop_last else $n_{iter} = \\lceil\\frac{epochs}{m}\\rceil$\n",
    "\n",
    "\n",
    "\n",
    "<ins>Gradients $g, g'$:\n",
    "\n",
    "$g^{(j)} = \\frac{1}{m}\\sum_{k=1}^m\\nabla_{\\theta_i}f(\\theta^{(k)})$ is the current gradient. $g'^{(j)} = \\frac{1}{m}\\sum_{k=m+1}^{2m}\\nabla_{\\theta_i}f(\\theta^{(k)})$ is the gradient calculated on the consecutive minibatch with the current parameters.\n",
    "\n",
    "\n",
    "<ins>Moving averages $E[x]_j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    E[x]_j &= \\frac{j-1}{j}\\sum_{l=1}^{j-1}x^{(l)} + \\frac{1}{j}x^{(j)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Or should we use Equation (23) for all updates of moving averages?\n",
    "\n",
    "TODO: clarify!\n",
    "\n",
    "\n",
    "<ins>Elements of the Hessian diagnonal $\\alpha_i$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\alpha_i &= \\nabla_{\\theta_i}f(\\theta + \\Delta) - \\nabla_{\\theta_i}f(\\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- \"The Equation 13 can be easily computed in a stochastic setting from the consecutive minibatches\":\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\alpha_i^{(j)} &= \\nabla_{\\theta_i}f(\\theta^{(j-1)} + \\Delta^{(j-1)}) - \\nabla_{\\theta_i}f(\\theta^{(j-1)}) \\\\\n",
    "    &= \\nabla_{\\theta_i}f(\\theta^{(j)}) - \\nabla_{\\theta_i}f(\\theta^{(j-1)}) \\\\\n",
    "    &= g^{(j)} - g^{(j-1)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Alternatively (more correct regarding indices):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\alpha_i^{(j)} &= \\nabla_{\\theta_i}f^{(j)}(\\theta^{(j-1)} + \\Delta^{(j-1)}) - \\nabla_{\\theta_i}f^{(j)}(\\theta^{(j-1)}) \\\\\n",
    "    &= \\nabla_{\\theta_i}f^{(j)}(\\theta^{(j)}) - \\nabla_{\\theta_i}f^{(j)}(\\theta^{(j-1)}) \\\\\n",
    "    &= g^{(j)} - g'^{(j-1)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "TODO: clarify indeces and why we can leave 1/delta out\n",
    "\n",
    "\n",
    "<ins>Correction term $\\gamma$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\gamma_i &= \\frac{E[(g_i - g_i')(g_i - E[g_i]_j)]_j}{E[(g_i - E[g_i]_j)(g_i' - E[g_i]_j)]_j}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "<ins>Corrected gradient $\\tilde{g}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\tilde{g}_i &= \\frac{g_i + \\gamma_i E[g_i]_j}{1+\\gamma_i}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "<ins>Update moving averages $E[\\Delta^2]_j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    E[\\Delta_i^2]_j &= (1 - \\tau_i^{-1}[j])E[\\Delta_i^2]_{j-1} + \\tau_i^{-1}[j](t_i^{(j)}\\tilde{g}_i^{(j)})\\\\\n",
    "    &= (1 - \\tau_i^{-1}[j])E[\\Delta_i^2]_{j-1} + \\tau_i^{-1}[j](\\Delta^{(j-1)}(\\alpha_i^{(j)})^{-1}\\tilde{g}_i^{(j)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "TODO: clarify $t = \\alpha^{-1}$ (Equation (9), (13))\n",
    "TODO: clarify if for all -> change to $E[x]_j$\n",
    "\n",
    "\n",
    "<ins>Estimated learning rate $\\eta^{(j)}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\eta_i^{(j)} &= \\frac{\\sqrt{E[\\Delta_i^2]_j}}{\\sqrt{E[\\alpha_i^2]_j}} - \\frac{E[\\alpha_i\\Delta_i]_j}{E[\\alpha_i^2]_j}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "<ins>Update memory size:\n",
    "    \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\tau_i[j] &= (1 - \\frac{E^2[\\Delta_i]_{j-1}}{E[\\Delta_i^2]_{j-1}})\\tau_i[j-1] + 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "<ins>Update parameters:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\theta^{(j+1)} &= \\theta^{(j)} - \\eta^{(j)}\\cdot\\tilde{g}^{(j)}\\\\\n",
    "    &= \\theta^{(j)} - \\Delta^{(j)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\Delta^{(j)} &= \\eta^{(j)}\\cdot\\tilde{g}^{(j)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from more_itertools import peekable\n",
    "\n",
    "def adasecant_dataloader(dataset, batch_size, shuffle=False, drop_last=False):\n",
    "    data_loader = peekable(iter(data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)))\n",
    "    return data_loader\n",
    "\n",
    "data_loader = adasecant_dataloader(dataset_test, 60, True, True)\n",
    "for batch in data_loader:\n",
    "    #print('current', batch['y'])\n",
    "    try:\n",
    "        peek = data_loader.peek()\n",
    "        #print('next', peek['y'])\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, batch_size=1000):\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        yhat = model.forward(batch['X'].float().to(device))\n",
    "        y = batch['y'].long().to(device)\n",
    "        batch_loss = f_loss(yhat, y)\n",
    "        loss += batch_loss.item() * len(batch['X'])\n",
    "        correct += (torch.argmax(yhat, dim=1) == y).float().sum().item()\n",
    "    accuracy = correct / len(dataset)\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def get_scheduler(optimizer, base_lr, max_lr, epochs_per_cycle, len_dataset, batch_size):\n",
    "    if epochs_per_cycle is None:\n",
    "        epochs_per_cycle = epochs\n",
    "    iterations_per_cycle = epochs_per_cycle * (len_dataset // batch_size)\n",
    "    return torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=iterations_per_cycle / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, validation_set, batch_size=64, epochs=1, \n",
    "                f_loss=F.cross_entropy, epochs_per_cycle=None):\n",
    "    \n",
    "    optimizer = AdaSecant(model.parameters())\n",
    "    lr_history = []\n",
    "    validation_accuracy = []\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    # evaluate initial state of model\n",
    "    initial_training_loss, _ = evaluate_model(model, dataset)\n",
    "    epoch_losses.append(initial_training_loss)\n",
    "    validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracy.append(accuracy)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training and epoch loss logging\n",
    "        # drop last to avoid stochastic outliers in gradient update\n",
    "        data_loader = adasecant_dataloader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            \n",
    "            # prepare adasecant with current gradient\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = f_loss(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item() * len(batch['X'])\n",
    "            batch_loss.backward()\n",
    "            optimizer.pre_step()\n",
    "            \n",
    "            # run adasecant with next gradient (addiotionally to current gradient)\n",
    "            model.zero_grad()\n",
    "            try:\n",
    "                next_batch = data_loader.peek()\n",
    "                yhat = model.forward(next_batch['X'].float().to(device))\n",
    "                batch_loss = f_loss(yhat, next_batch['y'].long().to(device))\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            except:\n",
    "                # peek in first\n",
    "                pass\n",
    "            #return\n",
    "            \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss / len(dataset)}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # calculate validation loss and accuracy\n",
    "        validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return (np.array(epoch_losses) / len(dataset), \n",
    "            np.array(validation_losses) / len(validation_set), \n",
    "            validation_accuracy, \n",
    "            lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Epoch 1/1 - Loss: 2.351825848221779\n"
     ]
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "max_lr = 0.1\n",
    "batch_size = 16\n",
    "epochs = 1\n",
    "f_opt = AdaSecant\n",
    "f_loss = F.cross_entropy\n",
    "cycle = epochs\n",
    "\n",
    "training_loss, validation_loss, validation_accuracy, lr_history = train_model(model.to(device),\n",
    "                                                                              dataset_train,\n",
    "                                                                              dataset_test,\n",
    "                                                                              batch_size,\n",
    "                                                                              epochs,\n",
    "                                                                              f_loss,\n",
    "                                                                              cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x251cd454d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label='training loss')\n",
    "plt.plot(validation_loss, label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "#plt.ylim(0.0, 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x251cd65ab80>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08984375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_accuracy)\n",
    "print(max(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1045e0c59eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from google.colab import files\n",
    "\n",
    "with open('train_loss', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(training_loss)\n",
    "\n",
    "with open('val_loss', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_loss)\n",
    "\n",
    "with open('val_accuracy', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_accuracy)\n",
    "    \n",
    "with open('lr_history', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(lr_history)\n",
    "\n",
    "files.download('train_loss')\n",
    "files.download('val_loss')\n",
    "files.download('val_accuracy')\n",
    "files.download('lr_history')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
