{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist = False\n",
    "cifar10 = True\n",
    "cifar100 = False\n",
    "assert mnist ^ cifar10 ^ cifar100\n",
    "\n",
    "n_classes = 10\n",
    "if mnist:\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "if cifar10:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "if cifar100:\n",
    "    n_classes = 100\n",
    "    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "print(trainset)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([50000, 3, 32, 32])\n",
      "y_train: torch.Size([50000])\n",
      "X_test: torch.Size([10000, 3, 32, 32])\n",
      "y_test: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    if len(x_grey.size()) == 3:\n",
    "        helper = torch.unsqueeze(x_grey, 1)\n",
    "        return helper.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 1:\n",
    "        return x_grey.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 3:\n",
    "        return x_grey\n",
    "    elif len(x_grey.size()) == 4:\n",
    "        raise ValueError(f'The size of this image tensor is not valid.\\\n",
    "        A 4th order image tensor must have dim1==1 (grey-scale) or dim1==3 (rgb).\\\n",
    "        Unknown format cannot be transformed to rgb.')\n",
    "    else:\n",
    "        raise ValueError(f'The size of this image-tensor is not valid.\\\n",
    "        Must be either 3rd (grey-scale) order tensor or 4th order tensor (rgb).\\\n",
    "        Got order {len(x_grey.size())}')\n",
    "        \n",
    "def swap_data(X):\n",
    "    X1 = np.swapaxes(X, 1, 3)\n",
    "    X2 = np.swapaxes(X1, 2, 3)\n",
    "    return X2\n",
    "\n",
    "if mnist:\n",
    "    X_train_grey = trainset.train_data\n",
    "    X_train = to_rgb(X_train_grey)\n",
    "    X_test_grey = testset.test_data\n",
    "    X_test = to_rgb(X_test_grey)\n",
    "    y_train = trainset.train_labels\n",
    "    y_test = testset.test_labels\n",
    "else:\n",
    "    X_train = torch.tensor(swap_data(trainset.data))\n",
    "    y_train = torch.tensor(trainset.targets)\n",
    "    X_test = torch.tensor(swap_data(testset.data))\n",
    "    y_test = torch.tensor(testset.targets)\n",
    "    \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load, modifications and GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([256, 10])\n",
      "y_train: torch.Size([256])\n",
      "X_test: torch.Size([256, 10])\n",
      "y_test: torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([[ 0.2264, -0.0536,  0.1326,  0.1753,  0.0275, -0.1603, -0.2837, -0.0666,\n",
      "          0.1148, -0.2890],\n",
      "        [-0.2525,  0.3008, -0.2598, -0.2944, -0.3100,  0.1323,  0.2874,  0.1427,\n",
      "          0.2408, -0.1106],\n",
      "        [ 0.1658,  0.2984, -0.0193,  0.0705, -0.1418,  0.0238, -0.0773,  0.2843,\n",
      "         -0.1651,  0.2157],\n",
      "        [ 0.3152, -0.1201, -0.2060, -0.1173,  0.2938, -0.1681,  0.2172,  0.0620,\n",
      "         -0.0114,  0.2226],\n",
      "        [-0.3152,  0.0241,  0.1290, -0.2111,  0.2928, -0.1571,  0.3110,  0.1843,\n",
      "          0.2644,  0.0795],\n",
      "        [ 0.1328, -0.2653,  0.0713, -0.0504,  0.1326, -0.2787, -0.1822,  0.0278,\n",
      "          0.0985,  0.2592],\n",
      "        [ 0.1100,  0.0250, -0.1171, -0.2872, -0.1103,  0.0381, -0.0895,  0.1223,\n",
      "          0.2890, -0.1950],\n",
      "        [-0.2815,  0.1293, -0.2277,  0.2450,  0.0661,  0.1946,  0.2940, -0.2730,\n",
      "         -0.2926,  0.2070],\n",
      "        [-0.0143, -0.1900,  0.2759, -0.2870, -0.1065,  0.0481,  0.0392,  0.0934,\n",
      "         -0.1678, -0.2636],\n",
      "        [-0.0635, -0.2092,  0.0838, -0.2164, -0.0883,  0.0778,  0.2693,  0.0674,\n",
      "         -0.1484,  0.2682]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0869, -0.2339, -0.0950, -0.3036,  0.2539,  0.2235,  0.0262,  0.0912,\n",
      "        -0.2438,  0.0604], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2765, -0.2625,  0.2614, -0.1872, -0.2757, -0.1355, -0.0140,  0.1934,\n",
      "         -0.0817,  0.0960],\n",
      "        [ 0.0331,  0.1835, -0.1425,  0.1777, -0.0965, -0.2227,  0.1314,  0.0971,\n",
      "         -0.2586,  0.2346],\n",
      "        [ 0.2536,  0.1708,  0.0708,  0.3030,  0.0821, -0.2472,  0.2946,  0.1665,\n",
      "         -0.2947, -0.1106],\n",
      "        [-0.1897, -0.1421,  0.2628, -0.0655,  0.1289,  0.0531,  0.3107, -0.1060,\n",
      "          0.1405,  0.1730],\n",
      "        [-0.1830,  0.0429,  0.2754,  0.2629, -0.1220,  0.1655,  0.2209, -0.0019,\n",
      "          0.1158,  0.0759],\n",
      "        [ 0.0667, -0.2562,  0.2880, -0.1302,  0.2744,  0.0765,  0.0504,  0.0670,\n",
      "         -0.0662, -0.3135],\n",
      "        [ 0.2604, -0.2973, -0.1962, -0.0251,  0.1302, -0.2928, -0.0840, -0.0272,\n",
      "         -0.1403,  0.2682],\n",
      "        [ 0.1069,  0.1498, -0.1409,  0.1923, -0.0928,  0.2580, -0.1367,  0.2592,\n",
      "          0.2122,  0.1472],\n",
      "        [-0.1019, -0.2810, -0.2977, -0.2439, -0.0403, -0.2652, -0.2551, -0.2016,\n",
      "          0.2173,  0.0171],\n",
      "        [ 0.1342,  0.0542,  0.1052, -0.2916, -0.1700,  0.0113,  0.0983,  0.2020,\n",
      "          0.1773,  0.1274]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3152,  0.0426,  0.2426,  0.2675,  0.2974, -0.0729, -0.0830, -0.0569,\n",
      "        -0.0296, -0.0582], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "'''\n",
    "model = models.resnet18(pretrained=False) # set model here\n",
    "in_ftr = model.fc.in_features\n",
    "out_ftr = n_classes\n",
    "model.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "'''\n",
    "\n",
    "# redefining stuff for AdaSecant test runs\n",
    "X_train = torch.rand(256, 10)\n",
    "X_test = torch.rand(256, 10)\n",
    "y_train = torch.randint(10, (256,))\n",
    "y_test = torch.randint(10, (256,))\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "model = torch.nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10))\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check specs for GPU-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device name: NVIDIA GeForce 940MX\n",
      "cuda device id 0\n"
     ]
    }
   ],
   "source": [
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('cuda device name:', torch.cuda.get_device_name())\n",
    "print('cuda device id', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model and data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train.to(device)\n",
    "print('worked?', X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing AdaSecant\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import copy\n",
    "\n",
    "class AdaSecant(optim.Optimizer):\n",
    "    r\"\"\"Documentation\n",
    "    Basis copied from https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py.\n",
    "    Left out closure, momentum-related stuff, __setstate__ as it does not seem to be necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=None):\n",
    "        if lr is not None:\n",
    "            print('Warning: lr is not a parameter for AdaSecant. Your lr will be set to None')\n",
    "            lr = None\n",
    "        defaults = dict(lr=lr)\n",
    "        super().__init__(params, defaults)\n",
    "        self.ready = False\n",
    "        self.current_gradients = None\n",
    "        # here we need to introduce some attribute to save params/gradients from old batch.\n",
    "        self.moving_average_of_g = None\n",
    "        self.delta = None\n",
    "        self.memory_size = None\n",
    "        self.gradients = None\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def pre_step(self):\n",
    "        for group in self.param_groups:\n",
    "            d_p_list = []\n",
    "        \n",
    "            for p in group['params']:\n",
    "                    # subgrouping of parameters for each layer, bias and weights separately (each tensor)\n",
    "                    if p.grad is not None:\n",
    "                        d_p_list.append(copy.deepcopy(p.grad))\n",
    "        \n",
    "        self.current_gradients = d_p_list\n",
    "        self.ready = True\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.ready:\n",
    "            raise RuntimeError('You must perform optimizer.pre_step() before performing ' +\n",
    "                               'optimizer.step() when using AdaSecant.\\n' +\n",
    "                               'pre_step ensures that the gradient is saved while step will generate the ' +\n",
    "                               'gradient on the new batch.\\n' +\n",
    "                               'Recommended call sequence:' +\n",
    "                               ' \\n model.zero_grad(), \\n loss = ..., \\n loss.backwards(), \\n ' +\n",
    "                               'optimizer.pre_step(), \\n model.zero_grad(), \\n loss = ..., \\n ' +\n",
    "                               'loss.backwards(), \\n optimizer.step()')\n",
    "        else:\n",
    "            self.ready = False\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            # all parameters of a model seem to be contained within the same group\n",
    "            params_with_grad = []\n",
    "            next_gradients = []\n",
    "\n",
    "            for p in group['params']:\n",
    "                # subgrouping of parameters for each layer, bias and weights separately (each tensor)\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    next_gradients.append(p.grad)\n",
    "            \n",
    "            print('current')\n",
    "            print(self.current_gradients)\n",
    "            print('next')\n",
    "            print(next_gradients)\n",
    "            adasecant(self, params_with_grad, next_gradients)\n",
    "            \n",
    "        return #loss\n",
    "    \n",
    "def adasecant(optimizer: AdaSecant, params: List[torch.Tensor], next_gradients: List[torch.Tensor]):\n",
    "    # g[i] corresponds to param[i]    \n",
    "    for i, param in enumerate(params):\n",
    "        g = optimizer.current_gradients[i]\n",
    "        g_next = next_gradients[i]\n",
    "        if i == 0:\n",
    "            print(param[0])\n",
    "            #print(g)\n",
    "            #print(g_next)\n",
    "        \n",
    "        correction_term = None # to be implemented\n",
    "        corrected_gradient = None # to be implemented\n",
    "        \n",
    "        \n",
    "    # update all attributes in optimizer\n",
    "    optimizer.gradients = g\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from more_itertools import peekable\n",
    "\n",
    "def adasecant_dataloader(dataset, batch_size, shuffle=False, drop_last=False):\n",
    "    data_loader = peekable(iter(data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)))\n",
    "    return data_loader\n",
    "\n",
    "data_loader = adasecant_dataloader(dataset_test, 60, True, True)\n",
    "for batch in data_loader:\n",
    "    #print('current', batch['y'])\n",
    "    try:\n",
    "        peek = data_loader.peek()\n",
    "        #print('next', peek['y'])\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, batch_size=1000):\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        yhat = model.forward(batch['X'].float().to(device))\n",
    "        y = batch['y'].long().to(device)\n",
    "        batch_loss = f_loss(yhat, y)\n",
    "        loss += batch_loss.item() * len(batch['X'])\n",
    "        correct += (torch.argmax(yhat, dim=1) == y).float().sum().item()\n",
    "    accuracy = correct / len(dataset)\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def get_scheduler(optimizer, base_lr, max_lr, epochs_per_cycle, len_dataset, batch_size):\n",
    "    if epochs_per_cycle is None:\n",
    "        epochs_per_cycle = epochs\n",
    "    iterations_per_cycle = epochs_per_cycle * (len_dataset // batch_size)\n",
    "    return torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=iterations_per_cycle / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, validation_set, batch_size=64, epochs=1, \n",
    "                f_loss=F.cross_entropy, epochs_per_cycle=None):\n",
    "    \n",
    "    optimizer = AdaSecant(model.parameters())\n",
    "    lr_history = []\n",
    "    validation_accuracy = []\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    # evaluate initial state of model\n",
    "    initial_training_loss, _ = evaluate_model(model, dataset)\n",
    "    epoch_losses.append(initial_training_loss)\n",
    "    validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracy.append(accuracy)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training and epoch loss logging\n",
    "        # drop last to avoid stochastic outliers in gradient update\n",
    "        data_loader = adasecant_dataloader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            \n",
    "            # prepare adasecant with current gradient\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = f_loss(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item() * len(batch['X'])\n",
    "            batch_loss.backward()\n",
    "            for param in model.parameters():\n",
    "                print(param.grad[0])\n",
    "            optimizer.pre_step()\n",
    "            \n",
    "            # run adasecant with next gradient (addiotionally to current gradient)\n",
    "            model.zero_grad()\n",
    "            try:\n",
    "                next_batch = data_loader.peek()\n",
    "                yhat = model.forward(next_batch['X'].float().to(device))\n",
    "                batch_loss = f_loss(yhat, next_batch['y'].long().to(device))\n",
    "                batch_loss.backward()\n",
    "                for param in model.parameters():\n",
    "                    print(param.grad[0])\n",
    "                optimizer.step()\n",
    "            except:\n",
    "                # whatever happens if there is no next gradient\n",
    "                pass\n",
    "            #return\n",
    "            \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss / len(dataset)}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # calculate validation loss and accuracy\n",
    "        validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return (np.array(epoch_losses) / len(dataset), \n",
    "            np.array(validation_losses) / len(validation_set), \n",
    "            validation_accuracy, \n",
    "            lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0104, -0.0096, -0.0043, -0.0057,  0.0012, -0.0162, -0.0043, -0.0025,\n",
      "        -0.0054, -0.0082], device='cuda:0')\n",
      "tensor(-0.0133, device='cuda:0')\n",
      "tensor([ 0.0022, -0.0120,  0.0087, -0.0109, -0.0005, -0.0018,  0.0048,  0.0035,\n",
      "        -0.0211, -0.0084], device='cuda:0')\n",
      "tensor(0.0420, device='cuda:0')\n",
      "tensor([-0.0167, -0.0195, -0.0319, -0.0174, -0.0145, -0.0241, -0.0125, -0.0077,\n",
      "        -0.0146, -0.0106], device='cuda:0')\n",
      "tensor(-0.0372, device='cuda:0')\n",
      "tensor([ 0.0025, -0.0215,  0.0038, -0.0137,  0.0127,  0.0019, -0.0094,  0.0047,\n",
      "        -0.0092,  0.0006], device='cuda:0')\n",
      "tensor(0.0394, device='cuda:0')\n",
      "current\n",
      "[tensor([[-0.0104, -0.0096, -0.0043, -0.0057,  0.0012, -0.0162, -0.0043, -0.0025,\n",
      "         -0.0054, -0.0082],\n",
      "        [-0.0022,  0.0060,  0.0082, -0.0039,  0.0088, -0.0042,  0.0055,  0.0138,\n",
      "          0.0081,  0.0184],\n",
      "        [ 0.0099,  0.0060, -0.0018,  0.0018,  0.0044,  0.0140,  0.0065,  0.0102,\n",
      "          0.0129,  0.0021],\n",
      "        [-0.0119, -0.0045,  0.0125, -0.0152,  0.0039, -0.0124,  0.0027,  0.0172,\n",
      "          0.0008,  0.0136],\n",
      "        [-0.0065, -0.0097, -0.0015, -0.0085, -0.0011, -0.0170,  0.0053, -0.0027,\n",
      "         -0.0052, -0.0054],\n",
      "        [-0.0048, -0.0101, -0.0001, -0.0129, -0.0105, -0.0101, -0.0077, -0.0024,\n",
      "         -0.0023, -0.0026],\n",
      "        [-0.0013,  0.0071,  0.0031,  0.0018,  0.0126,  0.0013,  0.0129,  0.0141,\n",
      "          0.0112,  0.0110],\n",
      "        [ 0.0099,  0.0057,  0.0026,  0.0026,  0.0075,  0.0072, -0.0008,  0.0077,\n",
      "          0.0086,  0.0023],\n",
      "        [-0.0107, -0.0145, -0.0090, -0.0100, -0.0206, -0.0140, -0.0153, -0.0216,\n",
      "         -0.0135, -0.0111],\n",
      "        [-0.0112, -0.0001,  0.0025,  0.0089,  0.0044, -0.0037, -0.0055, -0.0027,\n",
      "         -0.0047, -0.0055]], device='cuda:0'), tensor([-0.0133,  0.0084,  0.0044, -0.0028, -0.0154, -0.0192,  0.0063,  0.0105,\n",
      "        -0.0267, -0.0014], device='cuda:0'), tensor([[ 2.2461e-03, -1.2021e-02,  8.6703e-03, -1.0860e-02, -5.4676e-04,\n",
      "         -1.7675e-03,  4.8202e-03,  3.4893e-03, -2.1148e-02, -8.4093e-03],\n",
      "        [-1.8066e-02, -1.2513e-02,  1.8797e-02, -8.7459e-04,  3.9257e-02,\n",
      "          1.0958e-02, -7.9528e-03,  1.3210e-02, -3.4514e-02,  7.7491e-03],\n",
      "        [-6.4415e-03,  1.5475e-03,  3.6099e-05,  9.7266e-03,  1.5313e-02,\n",
      "          8.6494e-03,  2.2914e-03, -3.4483e-03, -1.7614e-03,  6.9793e-03],\n",
      "        [ 1.4009e-03, -1.3995e-03, -6.1734e-03,  9.4457e-03,  6.9765e-03,\n",
      "          1.1172e-03, -6.4686e-03,  3.8076e-03,  1.3321e-03,  4.3673e-05],\n",
      "        [-5.7943e-03,  1.7261e-02,  9.5453e-04, -5.4118e-03, -5.8175e-03,\n",
      "         -5.0620e-03,  4.1090e-03, -6.2624e-03,  1.7664e-02,  7.6127e-03],\n",
      "        [-1.8060e-03,  5.2640e-03,  4.3108e-03,  7.7936e-03,  1.5733e-03,\n",
      "         -5.0418e-04,  6.3304e-03, -5.5945e-03, -1.1467e-04,  3.3035e-03],\n",
      "        [ 1.4291e-02,  1.7504e-03, -1.5653e-02, -6.6425e-03, -1.7765e-02,\n",
      "         -1.0413e-02, -2.7565e-03, -3.2134e-03,  2.2675e-02, -1.0293e-02],\n",
      "        [ 9.6489e-03, -3.7282e-03, -6.3438e-03,  4.1963e-03, -9.2705e-03,\n",
      "          7.4465e-03,  1.7446e-03, -1.6573e-02,  2.0042e-02,  1.7829e-03],\n",
      "        [-1.3145e-03,  7.5201e-04, -1.5361e-03, -3.3876e-03, -1.5982e-02,\n",
      "         -2.1000e-03, -3.0120e-03,  7.1633e-03,  3.5091e-03,  3.5482e-03],\n",
      "        [ 5.8349e-03,  3.0874e-03, -3.0632e-03, -3.9858e-03, -1.3738e-02,\n",
      "         -8.3248e-03,  8.9421e-04,  7.4216e-03, -7.6837e-03, -1.2317e-02]],\n",
      "       device='cuda:0'), tensor([ 0.0420,  0.0568,  0.0063, -0.0104, -0.0267,  0.0014, -0.0355, -0.0229,\n",
      "        -0.0044, -0.0067], device='cuda:0')]\n",
      "next\n",
      "[tensor([[-0.0167, -0.0195, -0.0319, -0.0174, -0.0145, -0.0241, -0.0125, -0.0077,\n",
      "         -0.0146, -0.0106],\n",
      "        [ 0.0084, -0.0022, -0.0163, -0.0149, -0.0066,  0.0003, -0.0044,  0.0165,\n",
      "          0.0014,  0.0014],\n",
      "        [ 0.0433,  0.0405,  0.0514,  0.0374,  0.0324,  0.0275,  0.0303,  0.0362,\n",
      "          0.0282,  0.0276],\n",
      "        [ 0.0117,  0.0055, -0.0111, -0.0002,  0.0059,  0.0051, -0.0041,  0.0261,\n",
      "          0.0108,  0.0107],\n",
      "        [ 0.0010,  0.0009,  0.0033,  0.0095,  0.0083, -0.0017, -0.0006,  0.0072,\n",
      "          0.0029,  0.0068],\n",
      "        [ 0.0001, -0.0152, -0.0146, -0.0167, -0.0224, -0.0093, -0.0122, -0.0068,\n",
      "         -0.0075, -0.0178],\n",
      "        [ 0.0421,  0.0373,  0.0372,  0.0310,  0.0337,  0.0272,  0.0258,  0.0446,\n",
      "          0.0325,  0.0364],\n",
      "        [ 0.0031, -0.0090, -0.0100, -0.0083, -0.0133, -0.0096, -0.0027,  0.0024,\n",
      "         -0.0095, -0.0122],\n",
      "        [-0.0249, -0.0299, -0.0289, -0.0364, -0.0324, -0.0159, -0.0208, -0.0377,\n",
      "         -0.0190, -0.0286],\n",
      "        [-0.0019, -0.0129, -0.0134, -0.0046, -0.0156, -0.0078, -0.0066, -0.0085,\n",
      "          0.0014, -0.0045]], device='cuda:0'), tensor([-0.0372, -0.0068,  0.0659,  0.0092,  0.0035, -0.0195,  0.0610, -0.0128,\n",
      "        -0.0477, -0.0073], device='cuda:0'), tensor([[ 2.5104e-03, -2.1454e-02,  3.7548e-03, -1.3702e-02,  1.2693e-02,\n",
      "          1.9201e-03, -9.3814e-03,  4.7212e-03, -9.2314e-03,  6.0945e-04],\n",
      "        [-6.9005e-03, -2.0943e-02,  2.1851e-02, -5.9481e-03,  2.6717e-02,\n",
      "          1.3545e-02, -6.5317e-03,  2.7946e-03, -3.1396e-02,  1.5761e-03],\n",
      "        [-9.8335e-03,  1.2413e-03,  1.1991e-02,  1.3770e-02,  1.6389e-02,\n",
      "          4.2097e-03,  2.4913e-03, -1.8322e-03, -7.6823e-03,  5.1341e-03],\n",
      "        [ 2.7447e-03, -1.9730e-02,  6.6101e-03, -4.6430e-03,  1.0445e-02,\n",
      "          1.3274e-02,  9.0515e-04, -8.8275e-03, -1.2611e-02,  3.1852e-03],\n",
      "        [-1.1480e-02, -7.1987e-03,  1.6086e-02, -3.0835e-03,  3.3222e-02,\n",
      "          9.7795e-03, -1.4156e-04,  6.2358e-03, -3.4848e-02, -9.6306e-04],\n",
      "        [ 1.7721e-03, -1.8768e-02,  8.8170e-03, -6.3732e-03,  1.3073e-02,\n",
      "          3.3150e-03, -1.2452e-02,  5.0398e-03, -1.0999e-02, -2.6663e-03],\n",
      "        [ 5.3614e-03,  1.6699e-03, -9.8067e-03,  3.8726e-03, -9.3681e-03,\n",
      "          2.6507e-03, -4.3809e-03,  5.3787e-03, -2.3004e-03, -5.8435e-03],\n",
      "        [ 2.0649e-02,  4.8899e-02, -3.2065e-02,  1.0839e-02, -7.7653e-02,\n",
      "         -2.4520e-02,  2.6436e-02, -2.5105e-02,  7.1129e-02, -5.2129e-03],\n",
      "        [-3.6555e-03,  2.1840e-02, -2.2272e-02, -1.8635e-03, -1.8072e-02,\n",
      "         -1.7749e-02,  1.6637e-05,  1.1832e-02,  2.5754e-02,  9.1871e-04],\n",
      "        [-1.1681e-03,  1.4443e-02, -4.9648e-03,  7.1324e-03, -7.4450e-03,\n",
      "         -6.4252e-03,  3.0384e-03, -2.3709e-04,  1.2186e-02,  3.2622e-03]],\n",
      "       device='cuda:0'), tensor([ 0.0394,  0.0549,  0.0078,  0.0364,  0.0501,  0.0220, -0.0190, -0.1187,\n",
      "        -0.0506, -0.0225], device='cuda:0')]\n",
      "tensor([ 0.2264, -0.0536,  0.1326,  0.1753,  0.0275, -0.1603, -0.2837, -0.0666,\n",
      "         0.1148, -0.2890], device='cuda:0', requires_grad=True)\n",
      "tensor([-0.0167, -0.0195, -0.0319, -0.0174, -0.0145, -0.0241, -0.0125, -0.0077,\n",
      "        -0.0146, -0.0106], device='cuda:0')\n",
      "tensor(-0.0372, device='cuda:0')\n",
      "tensor([ 0.0025, -0.0215,  0.0038, -0.0137,  0.0127,  0.0019, -0.0094,  0.0047,\n",
      "        -0.0092,  0.0006], device='cuda:0')\n",
      "tensor(0.0394, device='cuda:0')\n",
      "tensor([-0.0057,  0.0066, -0.0022, -0.0033,  0.0032,  0.0060,  0.0032,  0.0088,\n",
      "         0.0051, -0.0101], device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor([-0.0117, -0.0192,  0.0219, -0.0067,  0.0416,  0.0151, -0.0052,  0.0040,\n",
      "        -0.0379,  0.0049], device='cuda:0')\n",
      "tensor(0.0706, device='cuda:0')\n",
      "current\n",
      "[tensor([[-0.0167, -0.0195, -0.0319, -0.0174, -0.0145, -0.0241, -0.0125, -0.0077,\n",
      "         -0.0146, -0.0106],\n",
      "        [ 0.0084, -0.0022, -0.0163, -0.0149, -0.0066,  0.0003, -0.0044,  0.0165,\n",
      "          0.0014,  0.0014],\n",
      "        [ 0.0433,  0.0405,  0.0514,  0.0374,  0.0324,  0.0275,  0.0303,  0.0362,\n",
      "          0.0282,  0.0276],\n",
      "        [ 0.0117,  0.0055, -0.0111, -0.0002,  0.0059,  0.0051, -0.0041,  0.0261,\n",
      "          0.0108,  0.0107],\n",
      "        [ 0.0010,  0.0009,  0.0033,  0.0095,  0.0083, -0.0017, -0.0006,  0.0072,\n",
      "          0.0029,  0.0068],\n",
      "        [ 0.0001, -0.0152, -0.0146, -0.0167, -0.0224, -0.0093, -0.0122, -0.0068,\n",
      "         -0.0075, -0.0178],\n",
      "        [ 0.0421,  0.0373,  0.0372,  0.0310,  0.0337,  0.0272,  0.0258,  0.0446,\n",
      "          0.0325,  0.0364],\n",
      "        [ 0.0031, -0.0090, -0.0100, -0.0083, -0.0133, -0.0096, -0.0027,  0.0024,\n",
      "         -0.0095, -0.0122],\n",
      "        [-0.0249, -0.0299, -0.0289, -0.0364, -0.0324, -0.0159, -0.0208, -0.0377,\n",
      "         -0.0190, -0.0286],\n",
      "        [-0.0019, -0.0129, -0.0134, -0.0046, -0.0156, -0.0078, -0.0066, -0.0085,\n",
      "          0.0014, -0.0045]], device='cuda:0'), tensor([-0.0372, -0.0068,  0.0659,  0.0092,  0.0035, -0.0195,  0.0610, -0.0128,\n",
      "        -0.0477, -0.0073], device='cuda:0'), tensor([[ 2.5104e-03, -2.1454e-02,  3.7548e-03, -1.3702e-02,  1.2693e-02,\n",
      "          1.9201e-03, -9.3814e-03,  4.7212e-03, -9.2314e-03,  6.0945e-04],\n",
      "        [-6.9005e-03, -2.0943e-02,  2.1851e-02, -5.9481e-03,  2.6717e-02,\n",
      "          1.3545e-02, -6.5317e-03,  2.7946e-03, -3.1396e-02,  1.5761e-03],\n",
      "        [-9.8335e-03,  1.2413e-03,  1.1991e-02,  1.3770e-02,  1.6389e-02,\n",
      "          4.2097e-03,  2.4913e-03, -1.8322e-03, -7.6823e-03,  5.1341e-03],\n",
      "        [ 2.7447e-03, -1.9730e-02,  6.6101e-03, -4.6430e-03,  1.0445e-02,\n",
      "          1.3274e-02,  9.0515e-04, -8.8275e-03, -1.2611e-02,  3.1852e-03],\n",
      "        [-1.1480e-02, -7.1987e-03,  1.6086e-02, -3.0835e-03,  3.3222e-02,\n",
      "          9.7795e-03, -1.4156e-04,  6.2358e-03, -3.4848e-02, -9.6306e-04],\n",
      "        [ 1.7721e-03, -1.8768e-02,  8.8170e-03, -6.3732e-03,  1.3073e-02,\n",
      "          3.3150e-03, -1.2452e-02,  5.0398e-03, -1.0999e-02, -2.6663e-03],\n",
      "        [ 5.3614e-03,  1.6699e-03, -9.8067e-03,  3.8726e-03, -9.3681e-03,\n",
      "          2.6507e-03, -4.3809e-03,  5.3787e-03, -2.3004e-03, -5.8435e-03],\n",
      "        [ 2.0649e-02,  4.8899e-02, -3.2065e-02,  1.0839e-02, -7.7653e-02,\n",
      "         -2.4520e-02,  2.6436e-02, -2.5105e-02,  7.1129e-02, -5.2129e-03],\n",
      "        [-3.6555e-03,  2.1840e-02, -2.2272e-02, -1.8635e-03, -1.8072e-02,\n",
      "         -1.7749e-02,  1.6637e-05,  1.1832e-02,  2.5754e-02,  9.1871e-04],\n",
      "        [-1.1681e-03,  1.4443e-02, -4.9648e-03,  7.1324e-03, -7.4450e-03,\n",
      "         -6.4252e-03,  3.0384e-03, -2.3709e-04,  1.2186e-02,  3.2622e-03]],\n",
      "       device='cuda:0'), tensor([ 0.0394,  0.0549,  0.0078,  0.0364,  0.0501,  0.0220, -0.0190, -0.1187,\n",
      "        -0.0506, -0.0225], device='cuda:0')]\n",
      "next\n",
      "[tensor([[-5.7095e-03,  6.5545e-03, -2.1868e-03, -3.3092e-03,  3.1974e-03,\n",
      "          5.9565e-03,  3.2226e-03,  8.8129e-03,  5.1034e-03, -1.0103e-02],\n",
      "        [-2.9742e-03,  5.2983e-03,  3.3554e-03,  2.8923e-03,  5.0406e-03,\n",
      "         -1.4446e-03,  1.3856e-02,  1.0263e-02,  5.7865e-03,  1.0290e-02],\n",
      "        [ 2.0492e-02,  4.4165e-02,  3.3150e-02,  3.9673e-02,  3.0231e-02,\n",
      "          3.0590e-02,  3.8474e-02,  4.2994e-02,  2.9544e-02,  3.6222e-02],\n",
      "        [ 1.8294e-02,  3.2960e-02,  2.7136e-02,  1.9172e-02,  2.3433e-02,\n",
      "          2.4839e-02,  4.3199e-02,  4.2594e-02,  3.2049e-02,  4.3873e-02],\n",
      "        [-1.3130e-03,  9.7774e-03, -3.0630e-04, -1.2416e-03,  3.4485e-05,\n",
      "          7.6490e-03,  4.7444e-03,  2.6969e-03,  1.9246e-03,  3.3769e-04],\n",
      "        [-7.0887e-03, -1.8491e-03,  3.0311e-03,  1.0961e-02, -1.8127e-03,\n",
      "          6.9115e-04,  6.0550e-03,  5.6807e-03, -1.0751e-04,  4.7062e-03],\n",
      "        [ 2.0752e-02,  3.7727e-02,  2.4124e-02,  2.6875e-02,  2.1668e-02,\n",
      "          2.2439e-02,  3.6856e-02,  3.3978e-02,  2.5415e-02,  3.5920e-02],\n",
      "        [ 3.9991e-03,  2.1520e-02,  1.6562e-02,  1.7423e-02,  1.5274e-02,\n",
      "          1.3167e-02,  1.9181e-02,  2.7718e-02,  1.8864e-02,  1.1987e-02],\n",
      "        [-2.1007e-02, -4.9648e-02, -2.9899e-02, -2.0260e-02, -3.0041e-02,\n",
      "         -2.7278e-02, -3.4275e-02, -4.4591e-02, -3.5407e-02, -3.3791e-02],\n",
      "        [ 1.1994e-02, -3.5536e-03,  4.9734e-04,  2.4339e-03, -1.0663e-02,\n",
      "         -5.3475e-03, -1.1365e-03,  2.1485e-04,  4.0756e-03,  9.5989e-03]],\n",
      "       device='cuda:0'), tensor([ 0.0062,  0.0137,  0.0695,  0.0614,  0.0069,  0.0008,  0.0603,  0.0351,\n",
      "        -0.0717, -0.0006], device='cuda:0'), tensor([[-1.1687e-02, -1.9226e-02,  2.1852e-02, -6.6814e-03,  4.1603e-02,\n",
      "          1.5116e-02, -5.1787e-03,  4.0308e-03, -3.7874e-02,  4.9451e-03],\n",
      "        [ 1.0827e-03,  4.1973e-03,  6.1205e-04,  5.2199e-04, -1.4218e-03,\n",
      "          5.8433e-03,  2.1719e-03, -4.6722e-03,  1.1733e-03, -1.9989e-03],\n",
      "        [-2.4015e-02, -3.0813e-03,  1.3521e-02, -1.9782e-03,  5.0296e-02,\n",
      "          5.8738e-03, -1.4469e-03,  1.3942e-02, -3.1440e-02,  1.3031e-02],\n",
      "        [-4.8883e-03, -2.6718e-03,  9.4918e-03,  3.8474e-03, -8.3526e-03,\n",
      "          2.9644e-03, -5.5127e-03,  8.0855e-03, -1.0237e-02,  6.9652e-03],\n",
      "        [-1.3068e-02, -1.4379e-02,  1.1159e-02,  4.2041e-03,  2.8454e-02,\n",
      "          1.2360e-02, -8.4171e-03,  8.2562e-03, -2.1875e-02,  1.0097e-02],\n",
      "        [-7.8216e-04,  7.0994e-03, -1.8003e-03, -1.3559e-02,  6.9914e-03,\n",
      "         -9.8148e-03,  1.2195e-04,  5.0590e-03,  7.7612e-04, -8.0674e-03],\n",
      "        [-6.3779e-03, -2.3919e-03,  1.6548e-02, -5.9562e-03,  2.1354e-02,\n",
      "          5.4436e-03,  6.2773e-03, -4.6001e-03, -2.1311e-02,  1.2317e-03],\n",
      "        [-4.9277e-05,  9.9680e-03, -5.7837e-03,  1.4611e-03, -7.4043e-03,\n",
      "         -3.8302e-03,  7.9908e-04, -2.4527e-03,  1.2979e-02,  4.7157e-03],\n",
      "        [ 3.6924e-02,  1.5460e-02, -4.5805e-02,  2.0161e-02, -9.3000e-02,\n",
      "         -2.0053e-02,  8.2075e-03, -1.9689e-02,  7.8230e-02, -1.3704e-02],\n",
      "        [ 2.2862e-02,  5.0247e-03, -1.9795e-02, -2.0213e-03, -3.8520e-02,\n",
      "         -1.3904e-02,  2.9777e-03, -7.9595e-03,  2.9578e-02, -1.7214e-02]],\n",
      "       device='cuda:0'), tensor([ 0.0706, -0.0064,  0.0693,  0.0067,  0.0371,  0.0030,  0.0430, -0.0233,\n",
      "        -0.1455, -0.0544], device='cuda:0')]\n",
      "tensor([ 0.2264, -0.0536,  0.1326,  0.1753,  0.0275, -0.1603, -0.2837, -0.0666,\n",
      "         0.1148, -0.2890], device='cuda:0', requires_grad=True)\n",
      "tensor([-0.0057,  0.0066, -0.0022, -0.0033,  0.0032,  0.0060,  0.0032,  0.0088,\n",
      "         0.0051, -0.0101], device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor([-0.0117, -0.0192,  0.0219, -0.0067,  0.0416,  0.0151, -0.0052,  0.0040,\n",
      "        -0.0379,  0.0049], device='cuda:0')\n",
      "tensor(0.0706, device='cuda:0')\n",
      "tensor([-0.0056, -0.0082, -0.0147, -0.0098, -0.0073, -0.0095, -0.0091, -0.0040,\n",
      "        -0.0130, -0.0145], device='cuda:0')\n",
      "tensor(-0.0203, device='cuda:0')\n",
      "tensor([-0.0224, -0.0068,  0.0245,  0.0043,  0.0375,  0.0110, -0.0046,  0.0151,\n",
      "        -0.0423,  0.0082], device='cuda:0')\n",
      "tensor(0.0552, device='cuda:0')\n",
      "current\n",
      "[tensor([[-5.7095e-03,  6.5545e-03, -2.1868e-03, -3.3092e-03,  3.1974e-03,\n",
      "          5.9565e-03,  3.2226e-03,  8.8129e-03,  5.1034e-03, -1.0103e-02],\n",
      "        [-2.9742e-03,  5.2983e-03,  3.3554e-03,  2.8923e-03,  5.0406e-03,\n",
      "         -1.4446e-03,  1.3856e-02,  1.0263e-02,  5.7865e-03,  1.0290e-02],\n",
      "        [ 2.0492e-02,  4.4165e-02,  3.3150e-02,  3.9673e-02,  3.0231e-02,\n",
      "          3.0590e-02,  3.8474e-02,  4.2994e-02,  2.9544e-02,  3.6222e-02],\n",
      "        [ 1.8294e-02,  3.2960e-02,  2.7136e-02,  1.9172e-02,  2.3433e-02,\n",
      "          2.4839e-02,  4.3199e-02,  4.2594e-02,  3.2049e-02,  4.3873e-02],\n",
      "        [-1.3130e-03,  9.7774e-03, -3.0630e-04, -1.2416e-03,  3.4485e-05,\n",
      "          7.6490e-03,  4.7444e-03,  2.6969e-03,  1.9246e-03,  3.3769e-04],\n",
      "        [-7.0887e-03, -1.8491e-03,  3.0311e-03,  1.0961e-02, -1.8127e-03,\n",
      "          6.9115e-04,  6.0550e-03,  5.6807e-03, -1.0751e-04,  4.7062e-03],\n",
      "        [ 2.0752e-02,  3.7727e-02,  2.4124e-02,  2.6875e-02,  2.1668e-02,\n",
      "          2.2439e-02,  3.6856e-02,  3.3978e-02,  2.5415e-02,  3.5920e-02],\n",
      "        [ 3.9991e-03,  2.1520e-02,  1.6562e-02,  1.7423e-02,  1.5274e-02,\n",
      "          1.3167e-02,  1.9181e-02,  2.7718e-02,  1.8864e-02,  1.1987e-02],\n",
      "        [-2.1007e-02, -4.9648e-02, -2.9899e-02, -2.0260e-02, -3.0041e-02,\n",
      "         -2.7278e-02, -3.4275e-02, -4.4591e-02, -3.5407e-02, -3.3791e-02],\n",
      "        [ 1.1994e-02, -3.5536e-03,  4.9734e-04,  2.4339e-03, -1.0663e-02,\n",
      "         -5.3475e-03, -1.1365e-03,  2.1485e-04,  4.0756e-03,  9.5989e-03]],\n",
      "       device='cuda:0'), tensor([ 0.0062,  0.0137,  0.0695,  0.0614,  0.0069,  0.0008,  0.0603,  0.0351,\n",
      "        -0.0717, -0.0006], device='cuda:0'), tensor([[-1.1687e-02, -1.9226e-02,  2.1852e-02, -6.6814e-03,  4.1603e-02,\n",
      "          1.5116e-02, -5.1787e-03,  4.0308e-03, -3.7874e-02,  4.9451e-03],\n",
      "        [ 1.0827e-03,  4.1973e-03,  6.1205e-04,  5.2199e-04, -1.4218e-03,\n",
      "          5.8433e-03,  2.1719e-03, -4.6722e-03,  1.1733e-03, -1.9989e-03],\n",
      "        [-2.4015e-02, -3.0813e-03,  1.3521e-02, -1.9782e-03,  5.0296e-02,\n",
      "          5.8738e-03, -1.4469e-03,  1.3942e-02, -3.1440e-02,  1.3031e-02],\n",
      "        [-4.8883e-03, -2.6718e-03,  9.4918e-03,  3.8474e-03, -8.3526e-03,\n",
      "          2.9644e-03, -5.5127e-03,  8.0855e-03, -1.0237e-02,  6.9652e-03],\n",
      "        [-1.3068e-02, -1.4379e-02,  1.1159e-02,  4.2041e-03,  2.8454e-02,\n",
      "          1.2360e-02, -8.4171e-03,  8.2562e-03, -2.1875e-02,  1.0097e-02],\n",
      "        [-7.8216e-04,  7.0994e-03, -1.8003e-03, -1.3559e-02,  6.9914e-03,\n",
      "         -9.8148e-03,  1.2195e-04,  5.0590e-03,  7.7612e-04, -8.0674e-03],\n",
      "        [-6.3779e-03, -2.3919e-03,  1.6548e-02, -5.9562e-03,  2.1354e-02,\n",
      "          5.4436e-03,  6.2773e-03, -4.6001e-03, -2.1311e-02,  1.2317e-03],\n",
      "        [-4.9277e-05,  9.9680e-03, -5.7837e-03,  1.4611e-03, -7.4043e-03,\n",
      "         -3.8302e-03,  7.9908e-04, -2.4527e-03,  1.2979e-02,  4.7157e-03],\n",
      "        [ 3.6924e-02,  1.5460e-02, -4.5805e-02,  2.0161e-02, -9.3000e-02,\n",
      "         -2.0053e-02,  8.2075e-03, -1.9689e-02,  7.8230e-02, -1.3704e-02],\n",
      "        [ 2.2862e-02,  5.0247e-03, -1.9795e-02, -2.0213e-03, -3.8520e-02,\n",
      "         -1.3904e-02,  2.9777e-03, -7.9595e-03,  2.9578e-02, -1.7214e-02]],\n",
      "       device='cuda:0'), tensor([ 0.0706, -0.0064,  0.0693,  0.0067,  0.0371,  0.0030,  0.0430, -0.0233,\n",
      "        -0.1455, -0.0544], device='cuda:0')]\n",
      "next\n",
      "[tensor([[-0.0056, -0.0082, -0.0147, -0.0098, -0.0073, -0.0095, -0.0091, -0.0040,\n",
      "         -0.0130, -0.0145],\n",
      "        [-0.0148, -0.0193, -0.0170, -0.0116, -0.0235, -0.0187, -0.0208, -0.0098,\n",
      "         -0.0221, -0.0180],\n",
      "        [ 0.0190,  0.0288,  0.0108,  0.0237,  0.0277,  0.0115,  0.0269,  0.0154,\n",
      "          0.0172,  0.0233],\n",
      "        [ 0.0161,  0.0098,  0.0123,  0.0215, -0.0013,  0.0114,  0.0158,  0.0153,\n",
      "          0.0058,  0.0113],\n",
      "        [ 0.0104,  0.0061,  0.0073,  0.0154,  0.0161,  0.0073,  0.0165,  0.0061,\n",
      "          0.0117, -0.0020],\n",
      "        [-0.0032,  0.0034,  0.0072,  0.0145,  0.0048, -0.0127,  0.0066,  0.0027,\n",
      "          0.0008, -0.0019],\n",
      "        [ 0.0103,  0.0109, -0.0016,  0.0115,  0.0104,  0.0076,  0.0086,  0.0023,\n",
      "          0.0027,  0.0072],\n",
      "        [-0.0015,  0.0075, -0.0076, -0.0006,  0.0013, -0.0051, -0.0017,  0.0048,\n",
      "         -0.0032,  0.0050],\n",
      "        [-0.0140, -0.0142,  0.0029, -0.0078, -0.0120, -0.0208, -0.0122, -0.0121,\n",
      "         -0.0107, -0.0167],\n",
      "        [-0.0057,  0.0028, -0.0035, -0.0031, -0.0014,  0.0068, -0.0121, -0.0109,\n",
      "         -0.0034,  0.0068]], device='cuda:0'), tensor([-0.0203, -0.0362,  0.0300,  0.0156,  0.0185,  0.0035,  0.0082, -0.0070,\n",
      "        -0.0142,  0.0014], device='cuda:0'), tensor([[-2.2400e-02, -6.8121e-03,  2.4475e-02,  4.3234e-03,  3.7462e-02,\n",
      "          1.0966e-02, -4.5940e-03,  1.5096e-02, -4.2319e-02,  8.1779e-03],\n",
      "        [ 7.9803e-03,  1.4649e-02, -1.8837e-02, -2.9985e-03, -3.3460e-02,\n",
      "         -8.7571e-03,  6.9334e-03, -5.2088e-03,  2.7802e-02, -3.7714e-03],\n",
      "        [-2.9900e-03,  1.4033e-03,  1.6193e-02,  7.8157e-03,  1.7532e-03,\n",
      "         -1.9957e-03,  2.2395e-03, -2.9924e-03, -5.8489e-03,  2.8855e-03],\n",
      "        [-2.4814e-03, -2.1551e-02, -5.7162e-05, -6.1385e-03,  2.5060e-02,\n",
      "          7.7529e-03, -8.2384e-03,  1.5123e-02, -3.2669e-02, -5.8492e-03],\n",
      "        [-2.4153e-03, -4.6307e-03,  8.0117e-03, -1.8363e-03, -1.6719e-03,\n",
      "          7.3418e-04, -6.7447e-03,  1.7326e-03,  1.2036e-03,  7.6898e-03],\n",
      "        [ 1.6661e-03, -6.8414e-04, -7.0043e-03,  6.7459e-03,  1.5795e-02,\n",
      "          1.1238e-03, -8.8396e-04,  1.4831e-04, -3.3965e-03, -2.5755e-03],\n",
      "        [-1.3786e-02, -9.5716e-03,  1.1789e-02, -8.9680e-04,  2.0761e-02,\n",
      "          4.0158e-03, -4.9854e-03,  1.6361e-02, -2.9011e-02,  3.5264e-03],\n",
      "        [ 4.4959e-03, -5.9023e-03,  3.2258e-03, -6.3728e-03,  6.6976e-03,\n",
      "          2.8745e-03, -4.6961e-03, -2.2044e-03, -4.1460e-03, -3.4737e-03],\n",
      "        [ 1.4765e-02,  9.3910e-03, -1.8685e-02, -8.6786e-03, -2.4567e-02,\n",
      "         -3.2505e-03,  1.1724e-02, -2.4698e-02,  4.1511e-02,  2.5219e-03],\n",
      "        [ 1.5166e-02,  2.3708e-02, -1.9111e-02,  8.0365e-03, -4.7829e-02,\n",
      "         -1.3464e-02,  9.2462e-03, -1.3357e-02,  4.6874e-02, -9.1317e-03]],\n",
      "       device='cuda:0'), tensor([ 0.0552, -0.0518,  0.0097,  0.0504,  0.0045,  0.0032,  0.0436,  0.0084,\n",
      "        -0.0367, -0.0865], device='cuda:0')]\n",
      "tensor([ 0.2264, -0.0536,  0.1326,  0.1753,  0.0275, -0.1603, -0.2837, -0.0666,\n",
      "         0.1148, -0.2890], device='cuda:0', requires_grad=True)\n",
      "tensor([-0.0056, -0.0082, -0.0147, -0.0098, -0.0073, -0.0095, -0.0091, -0.0040,\n",
      "        -0.0130, -0.0145], device='cuda:0')\n",
      "tensor(-0.0203, device='cuda:0')\n",
      "tensor([-0.0224, -0.0068,  0.0245,  0.0043,  0.0375,  0.0110, -0.0046,  0.0151,\n",
      "        -0.0423,  0.0082], device='cuda:0')\n",
      "tensor(0.0552, device='cuda:0')\n",
      "Epoch 1/1 - Loss: 2.3546475172042847\n"
     ]
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "max_lr = 0.1\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "f_opt = AdaSecant\n",
    "f_loss = F.cross_entropy\n",
    "cycle = epochs\n",
    "\n",
    "training_loss, validation_loss, validation_accuracy, lr_history = train_model(model.to(device),\n",
    "                                                                              dataset_train,\n",
    "                                                                              dataset_test,\n",
    "                                                                              batch_size,\n",
    "                                                                              epochs,\n",
    "                                                                              f_loss,\n",
    "                                                                              cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22482bfaf70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label='training loss')\n",
    "plt.plot(validation_loss, label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "#plt.ylim(0.0, 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x224847db3d0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_accuracy)\n",
    "print(max(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1045e0c59eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from google.colab import files\n",
    "\n",
    "with open('train_loss', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(training_loss)\n",
    "\n",
    "with open('val_loss', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_loss)\n",
    "\n",
    "with open('val_accuracy', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_accuracy)\n",
    "    \n",
    "with open('lr_history', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(lr_history)\n",
    "\n",
    "files.download('train_loss')\n",
    "files.download('val_loss')\n",
    "files.download('val_accuracy')\n",
    "files.download('lr_history')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
