{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist = False\n",
    "cifar10 = True\n",
    "cifar100 = False\n",
    "assert mnist ^ cifar10 ^ cifar100\n",
    "\n",
    "n_classes = 10\n",
    "if mnist:\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "if cifar10:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "if cifar100:\n",
    "    n_classes = 100\n",
    "    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "print(trainset)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([50000, 3, 32, 32])\n",
      "y_train: torch.Size([50000])\n",
      "X_test: torch.Size([10000, 3, 32, 32])\n",
      "y_test: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    if len(x_grey.size()) == 3:\n",
    "        helper = torch.unsqueeze(x_grey, 1)\n",
    "        return helper.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 1:\n",
    "        return x_grey.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 3:\n",
    "        return x_grey\n",
    "    elif len(x_grey.size()) == 4:\n",
    "        raise ValueError(f'The size of this image tensor is not valid.\\\n",
    "        A 4th order image tensor must have dim1==1 (grey-scale) or dim1==3 (rgb).\\\n",
    "        Unknown format cannot be transformed to rgb.')\n",
    "    else:\n",
    "        raise ValueError(f'The size of this image-tensor is not valid.\\\n",
    "        Must be either 3rd (grey-scale) order tensor or 4th order tensor (rgb).\\\n",
    "        Got order {len(x_grey.size())}')\n",
    "        \n",
    "def swap_data(X):\n",
    "    X1 = np.swapaxes(X, 1, 3)\n",
    "    X2 = np.swapaxes(X1, 2, 3)\n",
    "    return X2\n",
    "\n",
    "if mnist:\n",
    "    X_train_grey = trainset.train_data\n",
    "    X_train = to_rgb(X_train_grey)\n",
    "    X_test_grey = testset.test_data\n",
    "    X_test = to_rgb(X_test_grey)\n",
    "    y_train = trainset.train_labels\n",
    "    y_test = testset.test_labels\n",
    "else:\n",
    "    X_train = torch.tensor(swap_data(trainset.data))\n",
    "    y_train = torch.tensor(trainset.targets)\n",
    "    X_test = torch.tensor(swap_data(testset.data))\n",
    "    y_test = torch.tensor(testset.targets)\n",
    "    \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load, modifications and GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([256, 10])\n",
      "y_train: torch.Size([256])\n",
      "X_test: torch.Size([256, 10])\n",
      "y_test: torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([[-0.2868, -0.2732, -0.0487,  0.2383, -0.2921,  0.1895, -0.1458,  0.2626,\n",
      "          0.1711, -0.0136],\n",
      "        [-0.0812, -0.1302,  0.0415,  0.1110,  0.0901,  0.2374,  0.0024, -0.2314,\n",
      "          0.0807,  0.2293],\n",
      "        [-0.0796, -0.1332,  0.1213,  0.0436,  0.0790, -0.2680,  0.0101,  0.2906,\n",
      "          0.1452, -0.0310],\n",
      "        [ 0.1652, -0.1986,  0.2829, -0.2801,  0.0079, -0.1744, -0.2577,  0.1739,\n",
      "          0.2772, -0.2265],\n",
      "        [-0.0540, -0.0880,  0.1038,  0.1846, -0.0877,  0.2054, -0.2341,  0.1143,\n",
      "          0.0829, -0.0511],\n",
      "        [ 0.1398, -0.2904,  0.2170, -0.1742,  0.0816, -0.1282,  0.2109,  0.2033,\n",
      "         -0.2817,  0.0726],\n",
      "        [-0.1133, -0.2296,  0.1033,  0.0791, -0.2491, -0.2182, -0.0364, -0.1760,\n",
      "          0.2887,  0.2652],\n",
      "        [-0.0169, -0.2855, -0.2214, -0.1993,  0.0026,  0.0827,  0.2587,  0.2792,\n",
      "         -0.1318, -0.2156],\n",
      "        [-0.3056, -0.3112, -0.2409, -0.2326,  0.0486, -0.1580, -0.2965, -0.1694,\n",
      "         -0.0018, -0.2460],\n",
      "        [ 0.3061, -0.0223, -0.2915, -0.1971,  0.1683,  0.1721, -0.1047, -0.2506,\n",
      "         -0.2244,  0.1653]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2158,  0.1076, -0.2115, -0.0641,  0.1909,  0.2648,  0.2238, -0.0698,\n",
      "         0.1670,  0.1803], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1596, -0.2617,  0.0821,  0.1730,  0.2809,  0.1688, -0.0904,  0.1079,\n",
      "         -0.0748, -0.1802],\n",
      "        [-0.0567,  0.0789,  0.2785, -0.2165,  0.3083, -0.1167, -0.0961,  0.2928,\n",
      "          0.1873, -0.3121],\n",
      "        [ 0.2550,  0.1484, -0.1182, -0.1206,  0.1746,  0.1116, -0.0150,  0.1975,\n",
      "          0.0747,  0.0802],\n",
      "        [ 0.2350,  0.3001,  0.1539, -0.2657,  0.2680, -0.1452,  0.2248,  0.0612,\n",
      "         -0.2464,  0.0510],\n",
      "        [-0.2595,  0.2099, -0.0964,  0.1224,  0.0467,  0.1113, -0.2691,  0.0067,\n",
      "         -0.1347, -0.0991],\n",
      "        [ 0.1804, -0.2018, -0.2023, -0.1490, -0.0194, -0.1615, -0.0824, -0.2136,\n",
      "          0.0093,  0.1491],\n",
      "        [-0.3041,  0.2373,  0.3139,  0.2580,  0.0140, -0.2881,  0.2396,  0.2360,\n",
      "          0.2023, -0.2304],\n",
      "        [ 0.2479,  0.2399,  0.2365, -0.1024, -0.0695,  0.0047, -0.2460, -0.0753,\n",
      "         -0.0297,  0.2881],\n",
      "        [ 0.1031, -0.2917,  0.3040,  0.3008,  0.1305, -0.0336,  0.1578, -0.2020,\n",
      "         -0.3087, -0.2941],\n",
      "        [-0.3140,  0.1434, -0.0279,  0.2048, -0.1444,  0.2002, -0.1442, -0.2774,\n",
      "         -0.2202,  0.1094]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2651,  0.2654,  0.0876,  0.0359,  0.1576,  0.0385,  0.1478,  0.2847,\n",
      "         0.2685,  0.2037], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "'''\n",
    "model = models.resnet18(pretrained=False) # set model here\n",
    "in_ftr = model.fc.in_features\n",
    "out_ftr = n_classes\n",
    "model.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "'''\n",
    "\n",
    "# redefining stuff for AdaSecant test runs\n",
    "X_train = torch.rand(256, 10)\n",
    "X_test = torch.rand(256, 10)\n",
    "y_train = torch.randint(10, (256,))\n",
    "y_test = torch.randint(10, (256,))\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "model = torch.nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10))\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check specs for GPU-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device name: NVIDIA GeForce 940MX\n",
      "cuda device id 0\n"
     ]
    }
   ],
   "source": [
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('cuda device name:', torch.cuda.get_device_name())\n",
    "print('cuda device id', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model and data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train.to(device)\n",
    "print('worked?', X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing AdaSecant\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "class AdaSecant(optim.Optimizer):\n",
    "    r\"\"\"Documentation\n",
    "    Basis copied from https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py.\n",
    "    Left out closure, momentum-related stuff, __setstate__ as it does not seem to be necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=None):\n",
    "        if lr is not None:\n",
    "            print('Warning: lr is not a parameter for AdaSecant. Your lr will be set to None')\n",
    "            lr = None\n",
    "        defaults = dict(lr=lr)\n",
    "        super().__init__(params, defaults)\n",
    "        # here we need to introduce some attribute to save params/gradients from old batch.\n",
    "        self.moving_average_of_g = None\n",
    "        self.delta = None\n",
    "        self.memory_size = None\n",
    "        self.gradients = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \"\"\"\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            # all parameters of a model seem to be contained within the same group\n",
    "            params_with_grad = []\n",
    "            d_p_list = []\n",
    "            \n",
    "            # ToDo: update old params/gradients\n",
    "\n",
    "            for p in group['params']:\n",
    "                # subgrouping of parameters for each layer, bias and weights separately (each tensor)\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    d_p_list.append(p.grad)\n",
    "                    state = self.state[p]\n",
    "\n",
    "            #adasecant(self, params_with_grad, d_p_list)\n",
    "            \n",
    "        return #loss\n",
    "    \n",
    "def adasecant(optimizer: AdaSecant, params: List[torch.Tensor], d_p_list: List[torch.Tensor]):\n",
    "    # d_p_list[i] corresponds to param[i]\n",
    "    for i, param in enumerate(params):\n",
    "        g = d_p_list[i]\n",
    "        correction_term = None # to be implemented\n",
    "        corrected_gradient = None # to be implemented\n",
    "        \n",
    "        \n",
    "    # update all attributes in optimizer\n",
    "    optimizer.gradients = g\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current tensor([4, 0, 5, 4, 3, 5, 6, 3, 8, 1, 6, 7, 5, 8, 0, 4, 9, 0, 9, 8, 1, 0, 1, 4,\n",
      "        5, 8, 8, 7, 2, 6, 7, 0, 0, 1, 8, 8, 3, 3, 3, 5, 7, 9, 4, 7, 0, 3, 2, 1,\n",
      "        9, 0, 6, 1, 6, 9, 3, 3, 9, 3, 2, 3])\n",
      "next tensor([6, 4, 3, 5, 2, 4, 5, 5, 1, 5, 9, 0, 1, 3, 9, 1, 3, 3, 5, 8, 7, 2, 9, 2,\n",
      "        1, 8, 2, 2, 5, 7, 2, 4, 7, 0, 1, 0, 3, 6, 6, 2, 8, 2, 4, 9, 9, 3, 2, 0,\n",
      "        6, 6, 8, 5, 4, 1, 5, 2, 1, 0, 9, 9])\n",
      "current tensor([6, 4, 3, 5, 2, 4, 5, 5, 1, 5, 9, 0, 1, 3, 9, 1, 3, 3, 5, 8, 7, 2, 9, 2,\n",
      "        1, 8, 2, 2, 5, 7, 2, 4, 7, 0, 1, 0, 3, 6, 6, 2, 8, 2, 4, 9, 9, 3, 2, 0,\n",
      "        6, 6, 8, 5, 4, 1, 5, 2, 1, 0, 9, 9])\n",
      "next tensor([0, 3, 5, 9, 5, 2, 5, 4, 3, 4, 1, 1, 2, 5, 1, 9, 1, 1, 7, 2, 5, 0, 9, 4,\n",
      "        8, 3, 7, 9, 8, 8, 1, 7, 4, 6, 5, 3, 6, 3, 7, 8, 6, 5, 6, 3, 6, 3, 2, 0,\n",
      "        8, 1, 0, 0, 4, 2, 7, 7, 4, 6, 7, 1])\n",
      "current tensor([0, 3, 5, 9, 5, 2, 5, 4, 3, 4, 1, 1, 2, 5, 1, 9, 1, 1, 7, 2, 5, 0, 9, 4,\n",
      "        8, 3, 7, 9, 8, 8, 1, 7, 4, 6, 5, 3, 6, 3, 7, 8, 6, 5, 6, 3, 6, 3, 2, 0,\n",
      "        8, 1, 0, 0, 4, 2, 7, 7, 4, 6, 7, 1])\n",
      "next tensor([2, 5, 2, 0, 7, 6, 0, 1, 4, 1, 5, 7, 8, 9, 5, 5, 2, 6, 4, 9, 3, 8, 4, 0,\n",
      "        8, 6, 4, 0, 8, 4, 2, 9, 3, 9, 1, 2, 5, 2, 0, 3, 6, 4, 1, 9, 2, 6, 4, 3,\n",
      "        2, 6, 6, 1, 2, 8, 0, 9, 1, 2, 9, 6])\n",
      "current tensor([2, 5, 2, 0, 7, 6, 0, 1, 4, 1, 5, 7, 8, 9, 5, 5, 2, 6, 4, 9, 3, 8, 4, 0,\n",
      "        8, 6, 4, 0, 8, 4, 2, 9, 3, 9, 1, 2, 5, 2, 0, 3, 6, 4, 1, 9, 2, 6, 4, 3,\n",
      "        2, 6, 6, 1, 2, 8, 0, 9, 1, 2, 9, 6])\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from more_itertools import peekable\n",
    "\n",
    "def adasecant_dataloader(dataset, batch_size, shuffle=False, drop_last=False):\n",
    "    data_loader = peekable(iter(data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)))\n",
    "    return data_loader\n",
    "\n",
    "data_loader = adasecant_dataloader(dataset_test, 60, True, True)\n",
    "for batch in data_loader:\n",
    "    print('current', batch['y'])\n",
    "    try:\n",
    "        peek = data_loader.peek()\n",
    "        print('next', peek['y'])\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, batch_size=1000):\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        yhat = model.forward(batch['X'].float().to(device))\n",
    "        y = batch['y'].long().to(device)\n",
    "        batch_loss = f_loss(yhat, y)\n",
    "        loss += batch_loss.item() * len(batch['X'])\n",
    "        correct += (torch.argmax(yhat, dim=1) == y).float().sum().item()\n",
    "    accuracy = correct / len(dataset)\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def get_scheduler(optimizer, base_lr, max_lr, epochs_per_cycle, len_dataset, batch_size):\n",
    "    if epochs_per_cycle is None:\n",
    "        epochs_per_cycle = epochs\n",
    "    iterations_per_cycle = epochs_per_cycle * (len_dataset // batch_size)\n",
    "    return torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=iterations_per_cycle / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, validation_set, batch_size=64, epochs=1, \n",
    "                f_loss=F.cross_entropy, epochs_per_cycle=None):\n",
    "    \n",
    "    optimizer = AdaSecant(model.parameters())\n",
    "    lr_history = []\n",
    "    validation_accuracy = []\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    # evaluate initial state of model\n",
    "    initial_training_loss, _ = evaluate_model(model, dataset)\n",
    "    epoch_losses.append(initial_training_loss)\n",
    "    validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracy.append(accuracy)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training and epoch loss logging\n",
    "        # drop last to avoid stochastic outliers in gradient update\n",
    "        data_loader = adasecant_dataloader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0\n",
    "        for batch in data_loader:            \n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = f_loss(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item() * len(batch['X'])\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss / len(dataset)}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # calculate validation loss and accuracy\n",
    "        validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return (np.array(epoch_losses) / len(dataset), \n",
    "            np.array(validation_losses) / len(validation_set), \n",
    "            validation_accuracy, \n",
    "            lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 2.3291382640600204\n"
     ]
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "max_lr = 0.1\n",
    "batch_size = 16\n",
    "epochs = 1\n",
    "f_opt = AdaSecant\n",
    "f_loss = F.cross_entropy\n",
    "cycle = epochs\n",
    "\n",
    "training_loss, validation_loss, validation_accuracy, lr_history = train_model(model.to(device),\n",
    "                                                                              dataset_train,\n",
    "                                                                              dataset_test,\n",
    "                                                                              batch_size,\n",
    "                                                                              epochs,\n",
    "                                                                              f_loss,\n",
    "                                                                              cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2290e361f70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label='training loss')\n",
    "plt.plot(validation_loss, label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "#plt.ylim(0.0, 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2290e4532b0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_accuracy)\n",
    "print(max(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1045e0c59eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from google.colab import files\n",
    "\n",
    "with open('train_loss', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(training_loss)\n",
    "\n",
    "with open('val_loss', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_loss)\n",
    "\n",
    "with open('val_accuracy', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_accuracy)\n",
    "    \n",
    "with open('lr_history', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(lr_history)\n",
    "\n",
    "files.download('train_loss')\n",
    "files.download('val_loss')\n",
    "files.download('val_accuracy')\n",
    "files.download('lr_history')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
