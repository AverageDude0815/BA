{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist = False\n",
    "cifar10 = True\n",
    "cifar100 = False\n",
    "assert mnist ^ cifar10 ^ cifar100\n",
    "\n",
    "n_classes = 10\n",
    "if mnist:\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "if cifar10:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "if cifar100:\n",
    "    n_classes = 100\n",
    "    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "print(trainset)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([50000, 3, 32, 32])\n",
      "y_train: torch.Size([50000])\n",
      "X_test: torch.Size([10000, 3, 32, 32])\n",
      "y_test: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    if len(x_grey.size()) == 3:\n",
    "        helper = torch.unsqueeze(x_grey, 1)\n",
    "        return helper.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 1:\n",
    "        return x_grey.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 3:\n",
    "        return x_grey\n",
    "    elif len(x_grey.size()) == 4:\n",
    "        raise ValueError(f'The size of this image tensor is not valid.\\\n",
    "        A 4th order image tensor must have dim1==1 (grey-scale) or dim1==3 (rgb).\\\n",
    "        Unknown format cannot be transformed to rgb.')\n",
    "    else:\n",
    "        raise ValueError(f'The size of this image-tensor is not valid.\\\n",
    "        Must be either 3rd (grey-scale) order tensor or 4th order tensor (rgb).\\\n",
    "        Got order {len(x_grey.size())}')\n",
    "        \n",
    "def swap_data(X):\n",
    "    X1 = np.swapaxes(X, 1, 3)\n",
    "    X2 = np.swapaxes(X1, 2, 3)\n",
    "    return X2\n",
    "\n",
    "if mnist:\n",
    "    X_train_grey = trainset.train_data\n",
    "    X_train = to_rgb(X_train_grey)\n",
    "    X_test_grey = testset.test_data\n",
    "    X_test = to_rgb(X_test_grey)\n",
    "    y_train = trainset.train_labels\n",
    "    y_test = testset.test_labels\n",
    "else:\n",
    "    X_train = torch.tensor(swap_data(trainset.data))\n",
    "    y_train = torch.tensor(trainset.targets)\n",
    "    X_test = torch.tensor(swap_data(testset.data))\n",
    "    y_test = torch.tensor(testset.targets)\n",
    "    \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load, modifications and GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([256, 10])\n",
      "y_train: torch.Size([256])\n",
      "X_test: torch.Size([256, 10])\n",
      "y_test: torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([[ 0.2286,  0.2287,  0.2141, -0.2615,  0.2510,  0.2675, -0.0139,  0.2971,\n",
      "         -0.3096,  0.2358],\n",
      "        [ 0.0334, -0.0859,  0.2492,  0.2291, -0.0631,  0.2375, -0.0705,  0.0684,\n",
      "         -0.1596, -0.2239],\n",
      "        [ 0.0791, -0.2795,  0.1702,  0.2287,  0.2801,  0.1053,  0.2536,  0.2046,\n",
      "          0.0809, -0.0134],\n",
      "        [ 0.0601,  0.1005, -0.2616, -0.0729,  0.2587, -0.3138,  0.1805, -0.0032,\n",
      "         -0.0248,  0.0057],\n",
      "        [-0.0312,  0.0801,  0.1542, -0.2747, -0.2268, -0.3161, -0.3042,  0.1204,\n",
      "         -0.0676,  0.0029],\n",
      "        [ 0.0564, -0.0028, -0.1799, -0.0803, -0.0600,  0.1863,  0.3100,  0.2410,\n",
      "         -0.0005,  0.1184],\n",
      "        [ 0.3038, -0.0399, -0.2349, -0.1069,  0.0366, -0.0655,  0.1577, -0.1473,\n",
      "          0.2123, -0.1129],\n",
      "        [ 0.1342, -0.2365,  0.0650,  0.0355,  0.0378, -0.0441,  0.3094,  0.1560,\n",
      "          0.2746,  0.2764],\n",
      "        [-0.2668, -0.0010, -0.2297,  0.2181,  0.0278, -0.2944, -0.1737,  0.1308,\n",
      "          0.0188, -0.2744],\n",
      "        [ 0.0276,  0.2441, -0.2618, -0.0242,  0.2447,  0.0019,  0.2353,  0.1177,\n",
      "         -0.1157,  0.0695]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2134, -0.1852,  0.0873,  0.0180, -0.2965,  0.2433, -0.0535, -0.0163,\n",
      "         0.1786, -0.0822], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1063,  0.1375, -0.1148, -0.0045,  0.1626,  0.1447,  0.1067,  0.2801,\n",
      "         -0.2405, -0.1291],\n",
      "        [ 0.2229,  0.2354, -0.1887, -0.1778, -0.0697,  0.0831,  0.2378,  0.1503,\n",
      "          0.2974, -0.0050],\n",
      "        [ 0.0243,  0.2782, -0.1855, -0.0225,  0.0997,  0.0240, -0.1346,  0.3145,\n",
      "          0.3014,  0.1109],\n",
      "        [ 0.1491, -0.1935,  0.1427,  0.2076, -0.2157, -0.2203, -0.2839,  0.2203,\n",
      "         -0.1476, -0.1793],\n",
      "        [ 0.2531,  0.0428, -0.0078, -0.1208,  0.2855, -0.2065, -0.1725,  0.0717,\n",
      "         -0.2770,  0.1939],\n",
      "        [ 0.1653, -0.2607, -0.1457, -0.0025,  0.0171,  0.0072,  0.1504,  0.0823,\n",
      "         -0.0995, -0.1545],\n",
      "        [ 0.0231, -0.1505,  0.2464,  0.1631,  0.2237,  0.1660, -0.0868, -0.1743,\n",
      "         -0.2306, -0.2102],\n",
      "        [-0.2402,  0.2033,  0.0244,  0.1387, -0.0491,  0.1225, -0.0092,  0.1446,\n",
      "          0.1414, -0.3016],\n",
      "        [-0.3016, -0.0415, -0.0444, -0.0178,  0.0653, -0.2362,  0.0622, -0.0547,\n",
      "         -0.0197, -0.1916],\n",
      "        [-0.1295,  0.1755, -0.2412, -0.2993, -0.1419, -0.1456,  0.1357, -0.1256,\n",
      "          0.0540,  0.1517]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2195,  0.2258, -0.0272,  0.2537,  0.1504,  0.1299,  0.0141,  0.2729,\n",
      "         0.2351, -0.2840], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "'''\n",
    "model = models.resnet18(pretrained=False) # set model here\n",
    "in_ftr = model.fc.in_features\n",
    "out_ftr = n_classes\n",
    "model.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "'''\n",
    "\n",
    "# redefining stuff for AdaSecant test runs\n",
    "X_train = torch.rand(256, 10)\n",
    "X_test = torch.rand(256, 10)\n",
    "y_train = torch.randint(10, (256,))\n",
    "y_test = torch.randint(10, (256,))\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "model = torch.nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10))\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check specs for GPU-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device name: NVIDIA GeForce 940MX\n",
      "cuda device id 0\n"
     ]
    }
   ],
   "source": [
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('cuda device name:', torch.cuda.get_device_name())\n",
    "print('cuda device id', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model and data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train.to(device)\n",
    "print('worked?', X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing AdaSecant\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class AdaSecant(optim.Optimizer):\n",
    "    r\"\"\"Documentation\n",
    "    Basis copied from https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py.\n",
    "    Left out closure, momentum-related stuff, __setstate__ as it does not seem to be necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=None):\n",
    "        if lr is not None:\n",
    "            print('Warning: lr is not a parameter for AdaSecant. Your lr will be set to None')\n",
    "            lr = None\n",
    "        defaults = dict(lr=lr)\n",
    "        super().__init__(params, defaults)\n",
    "        self.ready = False\n",
    "        self.current_gradients = None\n",
    "        # here we need to introduce some attribute to save params/gradients from old batch.\n",
    "        self.moving_average_of_g = None\n",
    "        self.delta = None\n",
    "        self.memory_size = None\n",
    "        self.gradients = None\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def pre_step(self):\n",
    "        for group in self.param_groups:\n",
    "            d_p_list = []\n",
    "        \n",
    "        for p in group['params']:\n",
    "                # subgrouping of parameters for each layer, bias and weights separately (each tensor)\n",
    "                if p.grad is not None:\n",
    "                    d_p_list.append(p.grad)\n",
    "        \n",
    "        self.current_gradients = d_p_list\n",
    "        self.ready = True\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.ready:\n",
    "            raise RuntimeError('You must perform optimizer.pre_step() before performing ' +\n",
    "                               'optimizer.step() when using AdaSecant.\\n' +\n",
    "                               'pre_step ensures that the gradient is saved while step will generate the ' +\n",
    "                               'gradient on the new batch.\\n' +\n",
    "                               'Recommended call sequence:' +\n",
    "                               ' \\n model.zero_grad(), \\n loss = ..., \\n loss.backwards(), \\n ' +\n",
    "                               'optimizer.pre_step(), \\n model.zero_grad(), \\n loss = ..., \\n ' +\n",
    "                               'loss.backwards(), \\n optimizer.step()')\n",
    "        else:\n",
    "            self.ready = False\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            # all parameters of a model seem to be contained within the same group\n",
    "            params_with_grad = []\n",
    "            next_gradients = []\n",
    "            \n",
    "            # ToDo: update old params/gradients\n",
    "\n",
    "            for p in group['params']:\n",
    "                # subgrouping of parameters for each layer, bias and weights separately (each tensor)\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    next_gradients.append(p.grad)\n",
    "            \n",
    "            print('current')\n",
    "            print(self.current_gradients)\n",
    "            print('next')\n",
    "            print(next_gradients)\n",
    "            adasecant(self, params_with_grad, next_gradients)\n",
    "            \n",
    "        return #loss\n",
    "    \n",
    "def adasecant(optimizer: AdaSecant, params: List[torch.Tensor], next_gradients: List[torch.Tensor]):\n",
    "    # g[i] corresponds to param[i]    \n",
    "    for i, param in enumerate(params):\n",
    "        g = optimizer.current_gradients[i]\n",
    "        g_next = next_gradients[i]\n",
    "        if i == 0:\n",
    "            print(param)\n",
    "            #print(g)\n",
    "            #print(g_next)\n",
    "        \n",
    "        correction_term = None # to be implemented\n",
    "        corrected_gradient = None # to be implemented\n",
    "        \n",
    "        \n",
    "    # update all attributes in optimizer\n",
    "    optimizer.gradients = g\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from more_itertools import peekable\n",
    "\n",
    "def adasecant_dataloader(dataset, batch_size, shuffle=False, drop_last=False):\n",
    "    data_loader = peekable(iter(data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)))\n",
    "    return data_loader\n",
    "\n",
    "data_loader = adasecant_dataloader(dataset_test, 60, True, True)\n",
    "for batch in data_loader:\n",
    "    #print('current', batch['y'])\n",
    "    try:\n",
    "        peek = data_loader.peek()\n",
    "        #print('next', peek['y'])\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, batch_size=1000):\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        yhat = model.forward(batch['X'].float().to(device))\n",
    "        y = batch['y'].long().to(device)\n",
    "        batch_loss = f_loss(yhat, y)\n",
    "        loss += batch_loss.item() * len(batch['X'])\n",
    "        correct += (torch.argmax(yhat, dim=1) == y).float().sum().item()\n",
    "    accuracy = correct / len(dataset)\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def get_scheduler(optimizer, base_lr, max_lr, epochs_per_cycle, len_dataset, batch_size):\n",
    "    if epochs_per_cycle is None:\n",
    "        epochs_per_cycle = epochs\n",
    "    iterations_per_cycle = epochs_per_cycle * (len_dataset // batch_size)\n",
    "    return torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=iterations_per_cycle / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, validation_set, batch_size=64, epochs=1, \n",
    "                f_loss=F.cross_entropy, epochs_per_cycle=None):\n",
    "    \n",
    "    optimizer = AdaSecant(model.parameters())\n",
    "    lr_history = []\n",
    "    validation_accuracy = []\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    # evaluate initial state of model\n",
    "    initial_training_loss, _ = evaluate_model(model, dataset)\n",
    "    epoch_losses.append(initial_training_loss)\n",
    "    validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracy.append(accuracy)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training and epoch loss logging\n",
    "        # drop last to avoid stochastic outliers in gradient update\n",
    "        data_loader = adasecant_dataloader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            \n",
    "            # prepare adasecant with current gradient\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = f_loss(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item() * len(batch['X'])\n",
    "            batch_loss.backward()\n",
    "            for param in model.parameters():\n",
    "                print(param.grad[0])\n",
    "            optimizer.pre_step()\n",
    "            \n",
    "            # run adasecant with next gradient (addiotionally to current gradient)\n",
    "            model.zero_grad()\n",
    "            try:\n",
    "                next_batch = data_loader.peek()\n",
    "                yhat = model.forward(next_batch['X'].float().to(device))\n",
    "                batch_loss = f_loss(yhat, next_batch['y'].long().to(device))\n",
    "                batch_loss.backward()\n",
    "                for param in model.parameters():\n",
    "                    print(param.grad[0])\n",
    "                optimizer.step()\n",
    "            except:\n",
    "                # whatever happens if there is no next gradient\n",
    "                pass\n",
    "            return\n",
    "            \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss / len(dataset)}')\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # calculate validation loss and accuracy\n",
    "        validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return (np.array(epoch_losses) / len(dataset), \n",
    "            np.array(validation_losses) / len(validation_set), \n",
    "            validation_accuracy, \n",
    "            lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0180, 0.0176, 0.0139, 0.0139, 0.0187, 0.0190, 0.0233, 0.0223, 0.0197,\n",
      "        0.0198], device='cuda:0')\n",
      "tensor(0.0356, device='cuda:0')\n",
      "tensor([ 0.0283, -0.0004,  0.0226,  0.0010, -0.0282,  0.0109,  0.0024,  0.0156,\n",
      "        -0.0169,  0.0064], device='cuda:0')\n",
      "tensor(0.0293, device='cuda:0')\n",
      "tensor([ 0.0047,  0.0017,  0.0078, -0.0019,  0.0145,  0.0112,  0.0129,  0.0112,\n",
      "         0.0118,  0.0046], device='cuda:0')\n",
      "tensor(0.0103, device='cuda:0')\n",
      "tensor([-0.0266, -0.0056, -0.0082,  0.0034,  0.0003, -0.0065,  0.0088, -0.0020,\n",
      "         0.0107, -0.0045], device='cuda:0')\n",
      "tensor(-0.0025, device='cuda:0')\n",
      "current\n",
      "[tensor([[ 0.0047,  0.0017,  0.0078, -0.0019,  0.0145,  0.0112,  0.0129,  0.0112,\n",
      "          0.0118,  0.0046],\n",
      "        [-0.0020,  0.0061,  0.0048,  0.0024,  0.0071,  0.0053, -0.0033,  0.0032,\n",
      "          0.0117, -0.0008],\n",
      "        [ 0.0040, -0.0021,  0.0013,  0.0021,  0.0020, -0.0010,  0.0069,  0.0054,\n",
      "         -0.0080,  0.0011],\n",
      "        [ 0.0097,  0.0057,  0.0032,  0.0084,  0.0026,  0.0016,  0.0087,  0.0074,\n",
      "         -0.0015,  0.0037],\n",
      "        [-0.0152, -0.0139, -0.0114, -0.0134, -0.0092, -0.0089, -0.0110, -0.0078,\n",
      "         -0.0117, -0.0118],\n",
      "        [ 0.0137,  0.0193,  0.0125,  0.0185,  0.0151,  0.0088,  0.0150,  0.0164,\n",
      "          0.0212,  0.0096],\n",
      "        [ 0.0043,  0.0117,  0.0061,  0.0112,  0.0025,  0.0027,  0.0055, -0.0004,\n",
      "          0.0153,  0.0073],\n",
      "        [ 0.0061,  0.0075,  0.0043,  0.0044,  0.0064,  0.0078,  0.0048,  0.0049,\n",
      "          0.0120,  0.0022],\n",
      "        [ 0.0093,  0.0202,  0.0165,  0.0112,  0.0129,  0.0154,  0.0056,  0.0141,\n",
      "          0.0149,  0.0082],\n",
      "        [-0.0147, -0.0137, -0.0072, -0.0183, -0.0023, -0.0018, -0.0135, -0.0059,\n",
      "         -0.0057, -0.0100]], device='cuda:0'), tensor([ 0.0103,  0.0097,  0.0013,  0.0098, -0.0204,  0.0310,  0.0147,  0.0122,\n",
      "         0.0253, -0.0199], device='cuda:0'), tensor([[-2.6597e-02, -5.6341e-03, -8.2375e-03,  3.4190e-03,  2.9120e-04,\n",
      "         -6.4697e-03,  8.7952e-03, -2.0459e-03,  1.0743e-02, -4.5166e-03],\n",
      "        [ 4.1956e-02, -3.1492e-03,  3.7484e-02, -1.8628e-03, -4.0670e-02,\n",
      "          2.8594e-02, -3.5214e-03,  2.7509e-02, -1.4788e-02,  1.0319e-02],\n",
      "        [-7.7643e-03,  4.9878e-03, -1.3996e-02, -3.7610e-03,  1.6148e-02,\n",
      "         -9.7304e-03, -2.9743e-03, -1.6140e-02,  8.0644e-03, -3.8273e-03],\n",
      "        [ 1.2214e-02,  1.4927e-03,  1.0899e-02,  1.5734e-03, -1.0319e-02,\n",
      "          9.1422e-03,  2.5218e-03,  8.7558e-03, -8.1930e-03,  5.1679e-03],\n",
      "        [-1.5362e-02,  3.3711e-03, -1.5546e-02, -1.1698e-03,  2.5446e-02,\n",
      "         -1.5538e-02, -1.5081e-03, -1.2676e-02,  7.7635e-05, -5.8622e-03],\n",
      "        [ 1.1530e-02, -4.1907e-03,  6.2147e-03,  8.0022e-04, -8.2161e-03,\n",
      "          8.2773e-03,  1.8535e-03,  9.3287e-03, -7.0657e-03,  3.6388e-03],\n",
      "        [ 6.9512e-03,  1.9039e-03,  8.0290e-03,  3.5895e-03, -4.0405e-03,\n",
      "          5.9945e-03, -2.2966e-03,  3.2066e-03,  3.1850e-03,  5.3084e-03],\n",
      "        [ 3.6854e-02, -5.1144e-03,  2.7751e-02,  1.7638e-03, -2.9978e-02,\n",
      "          2.1596e-02, -2.6864e-03,  2.1080e-02, -8.9829e-03,  8.7224e-03],\n",
      "        [-4.5190e-02,  7.7101e-03, -4.1818e-02, -4.8341e-03,  3.9845e-02,\n",
      "         -3.0867e-02, -2.0511e-03, -3.2429e-02,  1.1845e-02, -1.4226e-02],\n",
      "        [-1.4591e-02, -1.3772e-03, -1.0780e-02,  4.8179e-04,  1.1493e-02,\n",
      "         -1.0998e-02,  1.8674e-03, -6.5895e-03,  5.1148e-03, -4.7236e-03]],\n",
      "       device='cuda:0'), tensor([-0.0025,  0.0518, -0.0163,  0.0068, -0.0385,  0.0117,  0.0054,  0.0471,\n",
      "        -0.0514, -0.0142], device='cuda:0')]\n",
      "next\n",
      "[tensor([[ 0.0047,  0.0017,  0.0078, -0.0019,  0.0145,  0.0112,  0.0129,  0.0112,\n",
      "          0.0118,  0.0046],\n",
      "        [-0.0020,  0.0061,  0.0048,  0.0024,  0.0071,  0.0053, -0.0033,  0.0032,\n",
      "          0.0117, -0.0008],\n",
      "        [ 0.0040, -0.0021,  0.0013,  0.0021,  0.0020, -0.0010,  0.0069,  0.0054,\n",
      "         -0.0080,  0.0011],\n",
      "        [ 0.0097,  0.0057,  0.0032,  0.0084,  0.0026,  0.0016,  0.0087,  0.0074,\n",
      "         -0.0015,  0.0037],\n",
      "        [-0.0152, -0.0139, -0.0114, -0.0134, -0.0092, -0.0089, -0.0110, -0.0078,\n",
      "         -0.0117, -0.0118],\n",
      "        [ 0.0137,  0.0193,  0.0125,  0.0185,  0.0151,  0.0088,  0.0150,  0.0164,\n",
      "          0.0212,  0.0096],\n",
      "        [ 0.0043,  0.0117,  0.0061,  0.0112,  0.0025,  0.0027,  0.0055, -0.0004,\n",
      "          0.0153,  0.0073],\n",
      "        [ 0.0061,  0.0075,  0.0043,  0.0044,  0.0064,  0.0078,  0.0048,  0.0049,\n",
      "          0.0120,  0.0022],\n",
      "        [ 0.0093,  0.0202,  0.0165,  0.0112,  0.0129,  0.0154,  0.0056,  0.0141,\n",
      "          0.0149,  0.0082],\n",
      "        [-0.0147, -0.0137, -0.0072, -0.0183, -0.0023, -0.0018, -0.0135, -0.0059,\n",
      "         -0.0057, -0.0100]], device='cuda:0'), tensor([ 0.0103,  0.0097,  0.0013,  0.0098, -0.0204,  0.0310,  0.0147,  0.0122,\n",
      "         0.0253, -0.0199], device='cuda:0'), tensor([[-2.6597e-02, -5.6341e-03, -8.2375e-03,  3.4190e-03,  2.9120e-04,\n",
      "         -6.4697e-03,  8.7952e-03, -2.0459e-03,  1.0743e-02, -4.5166e-03],\n",
      "        [ 4.1956e-02, -3.1492e-03,  3.7484e-02, -1.8628e-03, -4.0670e-02,\n",
      "          2.8594e-02, -3.5214e-03,  2.7509e-02, -1.4788e-02,  1.0319e-02],\n",
      "        [-7.7643e-03,  4.9878e-03, -1.3996e-02, -3.7610e-03,  1.6148e-02,\n",
      "         -9.7304e-03, -2.9743e-03, -1.6140e-02,  8.0644e-03, -3.8273e-03],\n",
      "        [ 1.2214e-02,  1.4927e-03,  1.0899e-02,  1.5734e-03, -1.0319e-02,\n",
      "          9.1422e-03,  2.5218e-03,  8.7558e-03, -8.1930e-03,  5.1679e-03],\n",
      "        [-1.5362e-02,  3.3711e-03, -1.5546e-02, -1.1698e-03,  2.5446e-02,\n",
      "         -1.5538e-02, -1.5081e-03, -1.2676e-02,  7.7635e-05, -5.8622e-03],\n",
      "        [ 1.1530e-02, -4.1907e-03,  6.2147e-03,  8.0022e-04, -8.2161e-03,\n",
      "          8.2773e-03,  1.8535e-03,  9.3287e-03, -7.0657e-03,  3.6388e-03],\n",
      "        [ 6.9512e-03,  1.9039e-03,  8.0290e-03,  3.5895e-03, -4.0405e-03,\n",
      "          5.9945e-03, -2.2966e-03,  3.2066e-03,  3.1850e-03,  5.3084e-03],\n",
      "        [ 3.6854e-02, -5.1144e-03,  2.7751e-02,  1.7638e-03, -2.9978e-02,\n",
      "          2.1596e-02, -2.6864e-03,  2.1080e-02, -8.9829e-03,  8.7224e-03],\n",
      "        [-4.5190e-02,  7.7101e-03, -4.1818e-02, -4.8341e-03,  3.9845e-02,\n",
      "         -3.0867e-02, -2.0511e-03, -3.2429e-02,  1.1845e-02, -1.4226e-02],\n",
      "        [-1.4591e-02, -1.3772e-03, -1.0780e-02,  4.8179e-04,  1.1493e-02,\n",
      "         -1.0998e-02,  1.8674e-03, -6.5895e-03,  5.1148e-03, -4.7236e-03]],\n",
      "       device='cuda:0'), tensor([-0.0025,  0.0518, -0.0163,  0.0068, -0.0385,  0.0117,  0.0054,  0.0471,\n",
      "        -0.0514, -0.0142], device='cuda:0')]\n",
      "Parameter containing:\n",
      "tensor([[ 0.2286,  0.2287,  0.2141, -0.2615,  0.2510,  0.2675, -0.0139,  0.2971,\n",
      "         -0.3096,  0.2358],\n",
      "        [ 0.0334, -0.0859,  0.2492,  0.2291, -0.0631,  0.2375, -0.0705,  0.0684,\n",
      "         -0.1596, -0.2239],\n",
      "        [ 0.0791, -0.2795,  0.1702,  0.2287,  0.2801,  0.1053,  0.2536,  0.2046,\n",
      "          0.0809, -0.0134],\n",
      "        [ 0.0601,  0.1005, -0.2616, -0.0729,  0.2587, -0.3138,  0.1805, -0.0032,\n",
      "         -0.0248,  0.0057],\n",
      "        [-0.0312,  0.0801,  0.1542, -0.2747, -0.2268, -0.3161, -0.3042,  0.1204,\n",
      "         -0.0676,  0.0029],\n",
      "        [ 0.0564, -0.0028, -0.1799, -0.0803, -0.0600,  0.1863,  0.3100,  0.2410,\n",
      "         -0.0005,  0.1184],\n",
      "        [ 0.3038, -0.0399, -0.2349, -0.1069,  0.0366, -0.0655,  0.1577, -0.1473,\n",
      "          0.2123, -0.1129],\n",
      "        [ 0.1342, -0.2365,  0.0650,  0.0355,  0.0378, -0.0441,  0.3094,  0.1560,\n",
      "          0.2746,  0.2764],\n",
      "        [-0.2668, -0.0010, -0.2297,  0.2181,  0.0278, -0.2944, -0.1737,  0.1308,\n",
      "          0.0188, -0.2744],\n",
      "        [ 0.0276,  0.2441, -0.2618, -0.0242,  0.2447,  0.0019,  0.2353,  0.1177,\n",
      "         -0.1157,  0.0695]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-01dedd327eac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcycle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m training_loss, validation_loss, validation_accuracy, lr_history = train_model(model.to(device),\n\u001b[0m\u001b[0;32m     10\u001b[0m                                                                               \u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                                               \u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "max_lr = 0.1\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "f_opt = AdaSecant\n",
    "f_loss = F.cross_entropy\n",
    "cycle = epochs\n",
    "\n",
    "training_loss, validation_loss, validation_accuracy, lr_history = train_model(model.to(device),\n",
    "                                                                              dataset_train,\n",
    "                                                                              dataset_test,\n",
    "                                                                              batch_size,\n",
    "                                                                              epochs,\n",
    "                                                                              f_loss,\n",
    "                                                                              cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25d11ca20d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhM0lEQVR4nO3deZgV5Zn38e/PphFZRBSSoGjaNcrSNNgaJhgRTYzoq7iN4ho1xsQ4URN1UGfiEidzkQwxhCTKuL5OQkReEDURd1H0jWIAEdkybqgEl5aETdBhueePU7RNU31ONfQ5vfD7XNe5rFP1VJ37sbnOfaqeqvtRRGBmZlbfDs0dgJmZtUxOEGZmlsoJwszMUjlBmJlZKicIMzNL1a65A2hK3bt3j4qKiuYOw8ys1Zg1a9ZHEdEjbVubShAVFRXMnDmzucMwM2s1JL3d0DZfYjIzs1ROEGZmlsoJwszMUjlBmJlZKicIMzNL5QRhZmapnCDMzCxVm3oOYqs9cjW8/2pzR2FmtnW+0A+GjWryw/oMwszMUvkMAoqSec3MWruinUFI2lPSNEkLJc2XdFlKm+GS5kqaI2mmpMPqbPtBst88SfdK6lCsWM3MbEvFvMS0HrgiIg4CBgGXSOpdr81TQP+IqAIuAO4AkLQHcClQHRF9gTJgRBFjNTOzeoqWICLivYiYnSyvAhYCe9Rrszo+mxS7E1B3gux2wE6S2gEdgaXFitXMzLZUkkFqSRXAAGBGyraTJC0CHiZ3FkFE/BUYDbwDvAesiIjHGzj2RcnlqZk1NTVF6oGZ2fan6AlCUmdgMnB5RKysvz0ipkTEgcCJwE3JPt2A4cDewO5AJ0lnpx0/Im6LiOqIqO7RI7WkuZmZbYWiJghJ5eSSw/iIuD9f24iYDuwrqTvwNeCtiKiJiHXA/cBXihmrmZltrph3MQm4E1gYETc30Ga/pB2SBgLtgWXkLi0NktQx2X4UuTEMMzMrkWI+BzEYOAd4VdKcZN21wF4AETEOOAU4V9I6YC1wejJoPUPSJGA2ubuhXgZuK2KsZmZWjz67iaj1q66uDk85amaWnaRZEVGdts2lNszMLJUThJmZpXKCMDOzVE4QZmaWygnCzMxSOUGYmVkqJwgzM0vlBGFmZqmcIMzMLJUThJmZpXKCMDOzVE4QZmaWygnCzMxSOUGYmVkqJwgzM0vlBGFmZqmcIMzMLJUThJmZpXKCMDOzVE4QZmaWygnCzMxSOUGYmVkqJwgzM0vlBGFmZqmcIMzMLJUThJmZpXKCMDOzVEVLEJL2lDRN0kJJ8yVdltJmuKS5kuZIminpsGT9l5J1m14rJV1erFjNzGxLBROEpH+U1CVZ/ldJ90samOHY64ErIuIgYBBwiaTe9do8BfSPiCrgAuAOgIj4S0RUJesPBtYAUzL2yczMmkCWM4gfRcSq5Nf9N4B7gFsL7RQR70XE7GR5FbAQ2KNem9UREcnbTkCwpaOANyLi7QyxmplZE8mSIDYk/z0OuDUiHgTaN+ZDJFUAA4AZKdtOkrQIeJjcWUR9I4B78xz7ouTy1MyamprGhGVmZnlkSRB/lfSfwGnAVEk7ZtwPAEmdgcnA5RGxsv72iJgSEQcCJwI31du3PXAC8P8aOn5E3BYR1RFR3aNHj6xhmZlZAVm+6E8DHgOOiYjlwK7AVVkOLqmcXHIYHxH352sbEdOBfSV1r7N6GDA7Ij7I8nlmZtZ0siSInsDDEfGapCOAfwReKrSTJAF3Agsj4uYG2uyXtCMZ+G4PLKvT5AzyXF4yM7PiaZehzWSgWtJ+5L7wHwJ+DxxbYL/BwDnAq5LmJOuuBfYCiIhxwCnAuZLWAWuB0zcNWkvqCHwd+E5jOmRmZk0jS4LYGBHrJZ0MjImIX0l6udBOEfE8oAJtfgr8tIFta4DdMsRnZmZFkOUS0zpJZwDnAn9M1pUXLyQzM2sJsiSI84F/AH4SEW9J2hv4XXHDMjOz5lYwQUTEAuBKcmMJfYElETGq6JGZmVmzKjgGkdy5dA+wmNyYwp6SvpnclmpmZm1UlkHqnwNHR8RfACQdQO7W04OLGZiZmTWvLGMQ5ZuSA0BE/DcepDYza/OynEHMlHQn8Nvk/VnArOKFZGZmLUGWBHExcAlwKbkxiOnAb4oZlJmZNb+CCSIiPgVuTl4ASPr/5J6UNjOzNmprZ5Tbq0mjMDOzFmdrE0TaxD5mZtaGNHiJKam9lLoJ2Kk44ZiZWUuRbwzi+Dzb/phnm5mZtQENJoiIOL+UgZiZWcuytWMQZmbWxjlBmJlZKicIMzNLVTBBSJop6RJJ3UoRkJmZtQxZziBGALsDf5Y0QdI3JOWdStTMzFq/LBMGvR4R/wIcAPweuAt4R9KNknYtdoBmZtY8Mo1BSKokNy/EfwCTgVOBlcDTxQvNzMyaU5YZ5WYBy4E7gauT4n0AMyS5YJ+ZWRuVpdz3P0bEm2kbIqKhchxmZtbKZbnEtELSWEmzJc2S9EtJuxU9MjMza1ZZEsQEoAY4hdzYQw1wXzGDMjOz5pflEtOuEXFTnff/JunEIsVjZmYtRJYziGmSRkjaIXmdBjxc7MDMzKx5ZUkQ3yH3/MP/JK8JwA8lrZK0sqGdJO0paZqkhZLmS7ospc1wSXMlzUme2D6szrZdJE2StCg5xj80vntmZra1ssxJ3WUrj70euCIiZkvqAsyS9ERELKjT5ingoYiI5FmLicCBybZfAo9GxKmS2gMdtzIOMzPbClnGIJB0AnB48vaZiCg4YVBEvAe8lyyvkrQQ2ANYUKfN6jq7dCKZylTSzsnnnZe023T2YmZmJZKlWN8o4DJyX+wLgMuSdZlJqgAGADNStp0kaRG5cY0LktX7kLtb6m5JL0u6Q1KnBo59UXJ5amZNTU1jwjIzszwUEfkbSHOBqojYmLwvA16OiMpMHyB1Bp4FfhIR9+dpdzhwXUR8TVI18CIwOCJmSPolsDIifpTvs6qrq2PmzJlZwjIzM3LVMiKiOm1b1vkgdqmz3LURH1xOrnbT+HzJASAipgP7SuoOLAGWRMSmM45JwMCsn2tmZtsuyxjEvwMvS5oGiNzYwDWFdkpKgt8JLIyImxtosx/wRjJIPRBoDyxL3r8r6UsR8RfgKOqMXZiZWfHlTRCSdgA2AoOAQ8gliJER8X6GYw8GzgFelTQnWXctsBdARIwj93T2uZLWAWuB0+Oza17fB8YndzC9CZzfiH6Zmdk2yjIGMT0iDs/bqIXwGISZWePkG4PIconpCUlXkqu/9PGmlRHxtyaKz8xasXXr1rFkyRI++eST5g7F8ujQoQO9evWivLw88z5ZEsSmW08vqbMuyN2KambbuSVLltClSxcqKirwbMQtU0SwbNkylixZwt577515vywJ4qCI2OyngaQOjQ3QzNqmTz75xMmhhZPEbrvtRmOfFctym+ufMq4zs+2Uk0PLtzV/owYThKQvSDoY2EnSAEkDk9cRuC6SmbUAy5cv55ZbbtmqfY899liWL1+et811113Hk08+uVXHr6+iooKPPvqoSY5VKvkuMX2DXC2kXkDd5xhWkbtd1cysWW1KEN/73ve22LZhwwbKysoa3Hfq1KkFj//jH/94m+Jr7Ro8g4iIeyJiKHBeRAyt8zqh0FPRZmalcPXVV/PGG29QVVXFVVddxTPPPMPQoUM588wz6devHwAnnngiBx98MH369OG2226r3XfTL/rFixdz0EEH8e1vf5s+ffpw9NFHs3btWgDOO+88Jk2aVNv++uuvZ+DAgfTr149FixYBUFNTw9e//nUGDhzId77zHb74xS8WPFO4+eab6du3L3379mXMmDEAfPzxxxx33HH079+fvn37ct9999X2sXfv3lRWVnLllVc26f+/QrIMUv9R0plARd32EbF9p1Yz28KNf5jPgqUNThOzVXrvvjPXH98ndduoUaOYN28ec+bMAeCZZ57hpZdeYt68ebV369x1113suuuurF27lkMOOYRTTjmF3XbbbbPjvPbaa9x7773cfvvtnHbaaUyePJmzzz57i8/r3r07s2fP5pZbbmH06NHccccd3HjjjRx55JFcc801PProo5sloTSzZs3i7rvvZsaMGUQEX/7ylxkyZAhvvvkmu+++Ow8/nJuPbcWKFfztb39jypQpLFq0CEkFL4k1tSyD1A8Cw8nN7/BxnZeZWYtz6KGHbnYr59ixY+nfvz+DBg3i3Xff5bXXXttin7333puqqioADj74YBYvXpx67JNPPnmLNs8//zwjRowA4JhjjqFbt25543v++ec56aST6NSpE507d+bkk0/mueeeo1+/fjz55JOMHDmS5557jq5du7LzzjvToUMHLrzwQu6//346dizt8G+WM4heEXFM0SMxs1avoV/6pdSp02czAzzzzDM8+eSTvPDCC3Ts2JEjjjgi9YG+HXfcsXa5rKys9hJTQ+3KyspYv349kHvGoDEaan/AAQcwa9Yspk6dyjXXXMPRRx/Nddddx0svvcRTTz3FhAkT+PWvf83TTz/dqM/bFpluc5XUr+iRmJk1UpcuXVi1alWD21esWEG3bt3o2LEjixYt4sUXX2zyGA477DAmTpwIwOOPP87f//73vO0PP/xwHnjgAdasWcPHH3/MlClT+OpXv8rSpUvp2LEjZ599NldeeSWzZ89m9erVrFixgmOPPZYxY8bUXkorlSxnEIcB50l6C/iUXMG+yDofhJlZsey2224MHjyYvn37MmzYMI477rjNth9zzDGMGzeOyspKvvSlLzFo0KAmj+H666/njDPO4L777mPIkCH07NmTLl0anql54MCBnHfeeRx66KEAXHjhhQwYMIDHHnuMq666ih122IHy8nJuvfVWVq1axfDhw/nkk0+ICH7xi180efz5ZCnW98W09RHxdlEi2gYu1mdWegsXLuSggw5q7jCazaeffkpZWRnt2rXjhRde4OKLLy75L/2s0v5WW1WsT9KREfF0RLwtae+IeKvOtpOBFpcgzMxK7Z133uG0005j48aNtG/fnttvv725Q2oy+S4xjeazWdwms/mMbv8K+FkIM9vu7b///rz88svNHUZR5BukVgPLae/NzKyNyZcgooHltPdmZtbG5LvEtI+kh8idLWxaJnmfvaC4mZm1SvkSxPA6y6Prbav/3szM2ph8xfqezfcqZZBmZk2lc+fOACxdupRTTz01tc0RRxxBoVvmx4wZw5o1a2rfZykfnsUNN9zA6NEt4zd4liepzczanN133722UuvWqJ8gpk6dyi677NIEkbUcThBm1mqNHDlyswmDbrjhBn7+85+zevVqjjrqqNrS3A8++OAW+y5evJi+ffsCsHbtWkaMGEFlZSWnn376ZrWYLr74Yqqrq+nTpw/XX389kCsAuHTpUoYOHcrQoUOBzScESivnna+seEPmzJnDoEGDqKys5KSTTqot4zF27NjaEuCbCgU+++yzVFVVUVVVxYABA/KWIMkqS6mNWpJ2ADpHRNPW8zWztuGRq+H9V5v2mF/oB8NGpW4aMWIEl19+ee2EQRMnTuTRRx+lQ4cOTJkyhZ133pmPPvqIQYMGccIJJzQ47eatt95Kx44dmTt3LnPnzmXgwM8e+/rJT37CrrvuyoYNGzjqqKOYO3cul156KTfffDPTpk2je/fumx2roXLe3bp1y1xWfJNzzz2XX/3qVwwZMoTrrruOG2+8kTFjxjBq1Cjeeustdtxxx9rLWqNHj+Y3v/kNgwcPZvXq1XTo0KEx/5dTFTyDkPR7STtL6gQsAP4i6apt/mQzs200YMAAPvzwQ5YuXcorr7xCt27d2GuvvYgIrr32WiorK/na177GX//6Vz744IMGjzN9+vTaL+rKykoqKz8rNTdx4kQGDhzIgAEDmD9/PgsWLMgbU0PlvCF7WXHIFRpcvnw5Q4YMAeCb3/wm06dPr43xrLPO4ne/+x3t2uV+5w8ePJgf/vCHjB07luXLl9eu3xZZjtA7IlZKOguYCowEZgH/sc2fbmZtSwO/9Ivp1FNPZdKkSbz//vu1l1vGjx9PTU0Ns2bNory8nIqKitQy33WlnV289dZbjB49mj//+c9069aN8847r+Bx8tW3y1pWvJCHH36Y6dOn89BDD3HTTTcxf/58rr76ao477jimTp3KoEGDePLJJznwwAO36vibZBmDKJdUDpwIPBgR6/CDcmbWQowYMYIJEyYwadKk2ruSVqxYwec+9znKy8uZNm0ab7+dv3Tc4Ycfzvjx4wGYN28ec+fOBWDlypV06tSJrl278sEHH/DII4/U7tNQqfGGynk3VteuXenWrVvt2cdvf/tbhgwZwsaNG3n33XcZOnQoP/vZz1i+fDmrV6/mjTfeoF+/fowcOZLq6uraKVG3RZYziP8EFgOvANOT6q4egzCzFqFPnz6sWrWKPfbYg549ewJw1llncfzxx1NdXU1VVVXBX9IXX3wx559/PpWVlVRVVdWW4u7fvz8DBgygT58+7LPPPgwePLh2n4suuohhw4bRs2dPpk2bVru+oXLe+S4nNeSee+7hu9/9LmvWrGGfffbh7rvvZsOGDZx99tmsWLGCiOAHP/gBu+yyCz/60Y+YNm0aZWVl9O7dm2HDhjX68+orWO47dSepXUSsL9BmT+C/gC8AG4HbIuKX9doMB25Ktq8HLo+I55Nti4FVwAZgfUPlaOtyuW+z0tvey323Jo0t951lkPqyZJBaku6UNBs4MkMs64ErIuIgYBBwiaTe9do8BfSPiCrgAuCOetuHRkRVluRgZmZNK8sYxAXJba1HAz2A84GCI1ER8V5EzE6WVwELgT3qtVkdn53CdMJjG2ZmLUaWBLFpaP9Y4O6IeIVGlvuWVAEMAGakbDtJ0iLgYXJnEZsE8LikWZIuynPsiyTNlDSzpqamMWGZmVkeWRLELEmPk0sQj0nqQm7MIBNJnclNOHR52gN2ETElIg4kd5fUTXU2DY6IgcAwcpenDk87fkTcFhHVEVHdo0ePrGGZWRPamrFMK62t+RtlSRDfAq4GDomINUB7cpeZCkpuj50MjI+IvDPQRcR0YF9J3ZP3S5P/fghMAQ7N8plmVlodOnRg2bJlThItWESwbNmyRj9dXfA214jYKKkXcGbyIMmzEfGHQvsp1/hOYGFE3NxAm/2ANyIiJA0kl3yWJU9t7xARq5Llo4EfZ+6VmZVMr169WLJkCb7E27J16NCBXr16NWqfgglC0ijgEGB8supSSV+JiGsK7DoYOAd4VdKcZN21wF4AETEOOAU4V9I6YC1wepIsPg9MSRJSO+D3EfFoo3pmZiVRXl7O3nt7DrG2qOBzEJLmAlURsTF5Xwa8HBGVeXdsBn4OwsyscbbpOYjELnWWu25zRGZm1uJlKbXx78DLkqaRu731cKDQ5SUzM2vl8iaIZP6HjeSehD6EXIIYGRHvlyA2MzNrRnkTRHIH0z9FxETgoRLFZGZmLUCWMYgnJF0paU9Ju256FT0yMzNrVlnGIDaVv7ikzroA9mn6cMzMrKXI8qCcb3A2M9sONXiJSdLZks5JWf9tSWcWNywzM2tu+cYgrgAeSFl/X7LNzMzasHwJoiyZx2EzSUXW8uKFZGZmLUG+BFGeFMrbTFLuu33xQjIzs5YgX4K4E5iUTPYD1E78MyHZZmZmbViDdzFFxGhJq4Fnk0l/AvgYGBURt5YqQDMzax6FnqQeB4xLEoTSxiTMzKxtyvKgHBGxutiBmJlZy5K13LeZmW1nnCDMzCxVpktMkr4CVNRtHxH/VaSYzMysBcgyJ/VvgX2BOcCGZHUAThBmZm1YljOIaqB3FJq82szM2pQsYxDzgC8UOxAzM2tZspxBdAcWSHoJ+HTTyog4oWhRmZlZs8uSIG4odhBmZtbyZJkw6NlSBGJmZi1LwTEISYMk/VnSakn/I2mDpJWlCM7MzJpPlkHqXwNnAK8BOwEXJuvMzKwNy1qL6XVJZRGxAbhb0p+KHJeZmTWzLGcQayS1B+ZI+pmkHwBbTCRUn6Q9JU2TtFDSfEmXpbQZLmmupDmSZko6rN72MkkvS/pj5h6ZmVmTyJIgzkna/RO5+SD2BE7JsN964IqIOAgYBFwiqXe9Nk8B/SOiCrgAuKPe9suAhRk+y8zMmljBBBERbwMCekbEjRHxw4h4PcN+70XE7GR5Fbkv+j3qtVld5wntTuRKeAAgqRdwHFsmDTMzK4EsdzEdT64O06PJ+ypJDzXmQ5KpSgcAM1K2nSRpEfAwubOITcYA/wxsLHDsi5LLUzNramoaE5aZmeWR5RLTDcChwHKAiJhDrrJrJslsdJOByyNii9tjI2JKRBwInAjclOzzf4API2JWoeNHxG0RUR0R1T169MgalpmZFZAlQayPiBVbc3BJ5eSSw/iIuD9f24iYDuwrqTswGDhB0mJgAnCkpN9tTQxmZrZ1MhXrk3QmUCZpf0m/Agre5ipJwJ3Awoi4uYE2+yXtkDQQaA8si4hrIqJXRFQAI4CnI+LsbF0yM7OmkOU5iO8D/0KuUN+9wGMkl4IKGEzuDqhXJc1J1l0L7AUQEePI3Q11rqR1wFrgdJcVNzNrGdSWvo+rq6tj5syZzR2GmVmrIWlWRFSnbWvwDKLQnUou921m1rblu8T0D8C75C4rzSD3LISZmW0n8iWILwBfJ1eo70xyzyncGxHzSxGYmZk1rwbvYoqIDRHxaER8k1ypjNeBZyR9v2TRmZlZs8l7F5OkHcmVuziD3MNxY4G8zzOYmVnbkG+Q+h6gL/AIcGNEzCtZVGZm1uzynUGcQ6566wHApcnzbJAbrI6I2LnIsZmZWTNqMEFERJanrM3MrI1yEjAzs1ROEGZmlsoJwszMUjlBmJlZKicIMzNL5QRhZmapnCDMzCyVE4SZmaVygjAzs1ROEGZmlsoJwszMUjlBmJlZKicIMzNL5QRhZmapnCDMzCyVE4SZmaVygjAzs1ROEGZmlsoJwszMUhUtQUjaU9I0SQslzZd0WUqb4ZLmSpojaaakw5L1HSS9JOmVZN8bixWnmZmla1fEY68HroiI2ZK6ALMkPRERC+q0eQp4KCJCUiUwETgQ+BQ4MiJWSyoHnpf0SES8WMR4zcysjqKdQUTEexExO1leBSwE9qjXZnVERPK2ExDJ+oiI1cn68uQVmJlZyZRkDEJSBTAAmJGy7SRJi4CHgQvqrC+TNAf4EHgiIrbYN2l3UXJ5amZNTU0xwjcz2y4VPUFI6gxMBi6PiJX1t0fElIg4EDgRuKnO+g0RUQX0Ag6V1Dft+BFxW0RUR0R1jx49itEFM7PtUlETRDJ+MBkYHxH352sbEdOBfSV1r7d+OfAMcEyRwjQzsxTFvItJwJ3Awoi4uYE2+yXtkDQQaA8sk9RD0i7J+p2ArwGLihWrmZltqZh3MQ0GzgFeTcYSAK4F9gKIiHHAKcC5ktYBa4HTkzuaegL3SCojl8QmRsQfixirmZnVU7QEERHPAyrQ5qfAT1PWzyU3qG1mZs3ET1KbmVkqJwgzM0vlBGFmZqmcIMzMLJUThJmZpXKCMDOzVMV8DqLVuPEP81mwdIsqIGZmrULv3Xfm+uP7NPlxfQZhZmapfAYBRcm8Zmatnc8gzMwslROEmZmlcoIwM7NUThBmZpbKCcLMzFI5QZiZWSonCDMzS+UEYWZmqRQRzR1Dk5FUA7y9lbt3Bz5qwnBaA/e57dve+gvuc2N9MSJ6pG1oUwliW0iaGRHVzR1HKbnPbd/21l9wn5uSLzGZmVkqJwgzM0vlBPGZ25o7gGbgPrd921t/wX1uMh6DMDOzVD6DMDOzVE4QZmaWartKEJKOkfQXSa9LujpluySNTbbPlTSwOeJsShn6fFbS17mS/iSpf3PE2ZQK9blOu0MkbZB0ainjK4YsfZZ0hKQ5kuZLerbUMTa1DP+2u0r6g6RXkj6f3xxxNhVJd0n6UNK8BrY3/fdXRGwXL6AMeAPYB2gPvAL0rtfmWOARQMAgYEZzx12CPn8F6JYsD9se+lyn3dPAVODU5o67BH/nXYAFwF7J+881d9wl6PO1wE+T5R7A34D2zR37NvT5cGAgMK+B7U3+/bU9nUEcCrweEW9GxP8AE4Dh9doMB/4rcl4EdpHUs9SBNqGCfY6IP0XE35O3LwK9ShxjU8vydwb4PjAZ+LCUwRVJlj6fCdwfEe8ARERr73eWPgfQRZKAzuQSxPrShtl0ImI6uT40pMm/v7anBLEH8G6d90uSdY1t05o0tj/fIvcLpDUr2GdJewAnAeNKGFcxZfk7HwB0k/SMpFmSzi1ZdMWRpc+/Bg4ClgKvApdFxMbShNcsmvz7q902hdO6KGVd/Xt8s7RpTTL3R9JQcgnisKJGVHxZ+jwGGBkRG3I/Llu9LH1uBxwMHAXsBLwg6cWI+O9iB1ckWfr8DWAOcCSwL/CEpOciYmWRY2suTf79tT0liCXAnnXe9yL3y6KxbVqTTP2RVAncAQyLiGUliq1YsvS5GpiQJIfuwLGS1kfEAyWJsOll/bf9UUR8DHwsaTrQH2itCSJLn88HRkXuAv3rkt4CDgReKk2IJdfk31/b0yWmPwP7S9pbUntgBPBQvTYPAecmdwMMAlZExHulDrQJFeyzpL2A+4FzWvGvyboK9jki9o6IioioACYB32vFyQGy/dt+EPiqpHaSOgJfBhaWOM6mlKXP75A7Y0LS54EvAW+WNMrSavLvr+3mDCIi1kv6J+AxcndA3BUR8yV9N9k+jtwdLccCrwNryP0CabUy9vk6YDfgluQX9fpoxZUwM/a5TcnS54hYKOlRYC6wEbgjIlJvl2wNMv6dbwL+r6RXyV1+GRkRrbYMuKR7gSOA7pKWANcD5VC87y+X2jAzs1Tb0yUmMzNrBCcIMzNL5QRhZmapnCDMzCyVE4SZmaVygjArIKn4OqfOq8EKsVtx7IqGqnOaNbft5jkIs22wNiKqmjsIs1LzGYTZVpK0WNJPJb2UvPZL1n9R0lNJTf6nkqfVkfR5SVOS+QlekfSV5FBlkm5P5ix4XNJOSftLJS1IjjOhmbpp2zEnCLPCdqp3ien0OttWRsSh5CqHjknW/Zpc2eVKYDwwNlk/Fng2IvqTq+s/P1m/P/CbiOgDLAdOSdZfDQxIjvPd4nTNrGF+ktqsAEmrI6JzyvrFwJER8aakcuD9iNhN0kdAz4hYl6x/LyK6S6oBekXEp3WOUQE8ERH7J+9HAuUR8W9JaYzVwAPAAxGxushdNduMzyDMtk00sNxQmzSf1lnewGdjg8cBvyFXpnuWJI8ZWkk5QZhtm9Pr/PeFZPlP5KqLApwFPJ8sPwVcDCCpTNLODR1U0g7AnhExDfhnclOGbnEWY1ZM/kViVthOkubUef9oRGy61XVHSTPI/dg6I1l3KXCXpKuAGj6rqnkZcJukb5E7U7gYaKgccxnwO0ldyVUi/UVELG+i/phl4jEIs62UjEFUt+YS0mb5+BKTmZml8hmEmZml8hmEmZmlcoIwM7NUThBmZpbKCcLMzFI5QZiZWar/BcN4Tsd6+jxiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label='training loss')\n",
    "plt.plot(validation_loss, label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "#plt.ylim(0.0, 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d12811c10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOHUlEQVR4nO3c34tc533H8fenUkQJSbFdybYsyV011UXVUogYhCG9CPUPJMVYvuiFDYmFcyEMNTi0wVXqf8CJoTGmxkakBpm4mEASIoyCYru5VeqVY8uoiuONSKqNFHuTCyfgCyHy7cUetevNSDu7Z1a76+f9gmHmnPOcmedhwG/NmVmnqpAkteuPVnoCkqSVZQgkqXGGQJIaZwgkqXGGQJIat36lJ7AUGzdurImJiZWehiStKSdPnvx1VW2av39NhmBiYoLJycmVnoYkrSlJfjFsv5eGJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxYwlBkj1J3k4yleTQkONJ8lR3/FSSXfOOr0vy4yQvjWM+kqTR9Q5BknXA08BeYCdwf5Kd84btBXZ0t4PAM/OOPwKc6TsXSdLijeMTwW5gqqrOVtVF4EVg/7wx+4Hna9YJ4LokmwGSbAU+B3xjDHORJC3SOEKwBTg3Z3u62zfqmCeBR4HfX+1FkhxMMplkcmZmpteEJUn/bxwhyJB9NcqYJHcD71XVyYVepKoOV9WgqgabNm1ayjwlSUOMIwTTwLY521uB8yOO+QxwT5KfM3tJ6e+SfHMMc5IkjWgcIXgN2JFke5INwH3A0XljjgIPdL8eug14v6ouVNVXqmprVU105/1nVX1+DHOSJI1ofd8nqKpLSR4GjgPrgOeq6nSSh7rjzwLHgH3AFPAB8GDf15UkjUeq5l/OX/0Gg0FNTk6u9DQkaU1JcrKqBvP3+5fFktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjRtLCJLsSfJ2kqkkh4YcT5KnuuOnkuzq9m9L8sMkZ5KcTvLIOOYjSRpd7xAkWQc8DewFdgL3J9k5b9heYEd3Owg80+2/BPxTVf0lcBvwD0POlSQto3F8ItgNTFXV2aq6CLwI7J83Zj/wfM06AVyXZHNVXaiq1wGq6nfAGWDLGOYkSRrROEKwBTg3Z3uaP/yP+YJjkkwAnwZ+NIY5SZJGNI4QZMi+WsyYJJ8Avg18qap+O/RFkoNJJpNMzszMLHmykqQPG0cIpoFtc7a3AudHHZPkY8xG4IWq+s6VXqSqDlfVoKoGmzZtGsO0JUkwnhC8BuxIsj3JBuA+4Oi8MUeBB7pfD90GvF9VF5IE+HfgTFX96xjmIklapPV9n6CqLiV5GDgOrAOeq6rTSR7qjj8LHAP2AVPAB8CD3emfAb4AvJXkjW7fv1TVsb7zkiSNJlXzL+evfoPBoCYnJ1d6GpK0piQ5WVWD+fv9y2JJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJatxYQpBkT5K3k0wlOTTkeJI81R0/lWTXqOdKkpZX7xAkWQc8DewFdgL3J9k5b9heYEd3Owg8s4hzJUnLaByfCHYDU1V1tqouAi8C++eN2Q88X7NOANcl2TziuZKkZTSOEGwBzs3Znu72jTJmlHMBSHIwyWSSyZmZmd6TliTNGkcIMmRfjThmlHNnd1YdrqpBVQ02bdq0yClKkq5k/RieYxrYNmd7K3B+xDEbRjhXkrSMxvGJ4DVgR5LtSTYA9wFH5405CjzQ/XroNuD9qrow4rmSpGXU+xNBVV1K8jBwHFgHPFdVp5M81B1/FjgG7AOmgA+AB692bt85SZJGl6qhl+RXtcFgUJOTkys9DUlaU5KcrKrB/P3+ZbEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjeoUgyQ1JXk7yTnd//RXG7UnydpKpJIfm7H8iyU+SnEry3STX9ZmPJGnx+n4iOAS8WlU7gFe77Q9Jsg54GtgL7ATuT7KzO/wy8NdV9TfAT4Gv9JyPJGmR+oZgP3Cke3wEuHfImN3AVFWdraqLwIvdeVTVD6rqUjfuBLC153wkSYvUNwQ3VdUFgO7+xiFjtgDn5mxPd/vm+yLw/Z7zkSQt0vqFBiR5Bbh5yKHHRnyNDNlX817jMeAS8MJV5nEQOAhw6623jvjSkqSFLBiCqrrjSseSvJtkc1VdSLIZeG/IsGlg25ztrcD5Oc9xALgbuL2qiiuoqsPAYYDBYHDFcZKkxel7aegocKB7fAD43pAxrwE7kmxPsgG4rzuPJHuAfwbuqaoPes5FkrQEfUPwOHBnkneAO7ttktyS5BhA92Xww8Bx4Azwrao63Z3/b8AngZeTvJHk2Z7zkSQt0oKXhq6mqn4D3D5k/3lg35ztY8CxIeP+os/rS5L68y+LJalxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxvUKQ5IYkLyd5p7u//grj9iR5O8lUkkNDjn85SSXZ2Gc+kqTF6/uJ4BDwalXtAF7ttj8kyTrgaWAvsBO4P8nOOce3AXcC/9NzLpKkJegbgv3Ake7xEeDeIWN2A1NVdbaqLgIvdudd9nXgUaB6zkWStAR9Q3BTVV0A6O5vHDJmC3BuzvZ0t48k9wC/rKo3F3qhJAeTTCaZnJmZ6TltSdJl6xcakOQV4OYhhx4b8TUyZF8l+Xj3HHeN8iRVdRg4DDAYDPz0IEljsmAIquqOKx1L8m6SzVV1Iclm4L0hw6aBbXO2twLngU8B24E3k1ze/3qS3VX1q0WsQZLUQ99LQ0eBA93jA8D3hox5DdiRZHuSDcB9wNGqequqbqyqiaqaYDYYu4yAJF1bfUPwOHBnkneY/eXP4wBJbklyDKCqLgEPA8eBM8C3qup0z9eVJI3JgpeGrqaqfgPcPmT/eWDfnO1jwLEFnmuiz1wkSUvjXxZLUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1LlW10nNYtCQzwC9Weh5LsBH49UpP4hpqbb3gmluxVtf8Z1W1af7ONRmCtSrJZFUNVnoe10pr6wXX3IqP2pq9NCRJjTMEktQ4Q3BtHV7pCVxjra0XXHMrPlJr9jsCSWqcnwgkqXGGQJIaZwjGKMkNSV5O8k53f/0Vxu1J8naSqSSHhhz/cpJKsnH5Z91P3zUneSLJT5KcSvLdJNdds8kv0gjvW5I81R0/lWTXqOeuVktdc5JtSX6Y5EyS00keufazX5o+73N3fF2SHyd56drNuqeq8jamG/A14FD3+BDw1SFj1gE/A/4c2AC8Ceycc3wbcJzZP5jbuNJrWu41A3cB67vHXx12/mq4LfS+dWP2Ad8HAtwG/GjUc1fjreeaNwO7usefBH76UV/znOP/CPwH8NJKr2fUm58Ixms/cKR7fAS4d8iY3cBUVZ2tqovAi915l30deBRYK9/i91pzVf2gqi51404AW5d3uku20PtGt/18zToBXJdk84jnrkZLXnNVXaiq1wGq6nfAGWDLtZz8EvV5n0myFfgc8I1rOem+DMF43VRVFwC6+xuHjNkCnJuzPd3tI8k9wC+r6s3lnugY9VrzPF9k9l9aq9Eoa7jSmFHXv9r0WfP/STIBfBr40finOHZ91/wks/+Q+/0yzW9ZrF/pCaw1SV4Bbh5y6LFRn2LIvkry8e457lrq3JbLcq153ms8BlwCXljc7K6ZBddwlTGjnLsa9Vnz7MHkE8C3gS9V1W/HOLflsuQ1J7kbeK+qTib57LgntpwMwSJV1R1XOpbk3csfi7uPiu8NGTbN7PcAl20FzgOfArYDbya5vP/1JLur6ldjW8ASLOOaLz/HAeBu4PbqLrKuQlddwwJjNoxw7mrUZ80k+RizEXihqr6zjPMcpz5r/nvgniT7gD8G/iTJN6vq88s43/FY6S8pPko34Ak+/MXp14aMWQ+cZfY/+pe/jPqrIeN+ztr4srjXmoE9wH8Dm1Z6LQusc8H3jdlrw3O/RPyvxbznq+3Wc80BngeeXOl1XKs1zxvzWdbQl8UrPoGP0g34U+BV4J3u/oZu/y3AsTnj9jH7K4qfAY9d4bnWSgh6rRmYYvZ66xvd7dmVXtNV1voHawAeAh7qHgd4ujv+FjBYzHu+Gm9LXTPwt8xeUjk1573dt9LrWe73ec5zrKkQ+L+YkKTG+ashSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWrc/wLouA/ZRwywxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_accuracy)\n",
    "print(max(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1045e0c59eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from google.colab import files\n",
    "\n",
    "with open('train_loss', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(training_loss)\n",
    "\n",
    "with open('val_loss', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_loss)\n",
    "\n",
    "with open('val_accuracy', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_accuracy)\n",
    "    \n",
    "with open('lr_history', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(lr_history)\n",
    "\n",
    "files.download('train_loss')\n",
    "files.download('val_loss')\n",
    "files.download('val_accuracy')\n",
    "files.download('lr_history')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
