{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist = False\n",
    "cifar10 = True\n",
    "cifar100 = False\n",
    "assert mnist ^ cifar10 ^ cifar100\n",
    "\n",
    "n_classes = 10\n",
    "if mnist:\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "if cifar10:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "if cifar100:\n",
    "    n_classes = 100\n",
    "    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=None)\n",
    "    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "print(trainset)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([50000, 3, 32, 32])\n",
      "y_train: torch.Size([50000])\n",
      "X_test: torch.Size([10000, 3, 32, 32])\n",
      "y_test: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def to_rgb(x_grey: torch.Tensor) -> torch.Tensor:\n",
    "    if len(x_grey.size()) == 3:\n",
    "        helper = torch.unsqueeze(x_grey, 1)\n",
    "        return helper.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 1:\n",
    "        return x_grey.repeat(1, 3, 1, 1).float()\n",
    "    elif len(x_grey.size()) == 4 and x_grey.size()[1] == 3:\n",
    "        return x_grey\n",
    "    elif len(x_grey.size()) == 4:\n",
    "        raise ValueError(f'The size of this image tensor is not valid.\\\n",
    "        A 4th order image tensor must have dim1==1 (grey-scale) or dim1==3 (rgb).\\\n",
    "        Unknown format cannot be transformed to rgb.')\n",
    "    else:\n",
    "        raise ValueError(f'The size of this image-tensor is not valid.\\\n",
    "        Must be either 3rd (grey-scale) order tensor or 4th order tensor (rgb).\\\n",
    "        Got order {len(x_grey.size())}')\n",
    "        \n",
    "def swap_data(X):\n",
    "    X1 = np.swapaxes(X, 1, 3)\n",
    "    X2 = np.swapaxes(X1, 2, 3)\n",
    "    return X2\n",
    "\n",
    "if mnist:\n",
    "    X_train_grey = trainset.train_data\n",
    "    X_train = to_rgb(X_train_grey)\n",
    "    X_test_grey = testset.test_data\n",
    "    X_test = to_rgb(X_test_grey)\n",
    "    y_train = trainset.train_labels\n",
    "    y_test = testset.test_labels\n",
    "else:\n",
    "    X_train = torch.tensor(swap_data(trainset.data))\n",
    "    y_train = torch.tensor(trainset.targets)\n",
    "    X_test = torch.tensor(swap_data(testset.data))\n",
    "    y_test = torch.tensor(testset.targets)\n",
    "    \n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load, modifications and GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([256, 10])\n",
      "y_train: torch.Size([256])\n",
      "X_test: torch.Size([256, 10])\n",
      "y_test: torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([[-0.0307,  0.1358, -0.0368, -0.0422,  0.3025, -0.1505,  0.0907,  0.2641,\n",
      "          0.1772, -0.0982],\n",
      "        [-0.0499, -0.2237,  0.0668,  0.0828,  0.2420, -0.2718,  0.0835,  0.2897,\n",
      "          0.1669,  0.2974],\n",
      "        [-0.2263, -0.3051,  0.0991, -0.2579,  0.0698, -0.0645,  0.1596, -0.2823,\n",
      "          0.2093,  0.3030],\n",
      "        [ 0.1678, -0.2800, -0.1675, -0.0903, -0.0736,  0.2535, -0.2156, -0.0693,\n",
      "          0.2214, -0.0740],\n",
      "        [ 0.0404, -0.0801, -0.0873, -0.0432, -0.2931, -0.2614, -0.2044,  0.3128,\n",
      "          0.3118,  0.2880],\n",
      "        [-0.0824,  0.0239,  0.3014, -0.0298, -0.3021, -0.0788, -0.0471, -0.1353,\n",
      "         -0.0611, -0.0636],\n",
      "        [-0.0420, -0.1355, -0.0762,  0.1873,  0.2776,  0.3024,  0.1973, -0.2825,\n",
      "          0.3017, -0.2270],\n",
      "        [ 0.2911,  0.1270, -0.2400,  0.0685, -0.1103, -0.2818,  0.1577, -0.0409,\n",
      "          0.2809,  0.2704],\n",
      "        [ 0.2723, -0.1110, -0.0573, -0.1249,  0.0560, -0.3064,  0.0026, -0.1962,\n",
      "          0.0152,  0.1414],\n",
      "        [ 0.1333,  0.0979,  0.2745,  0.1944, -0.3043,  0.2162,  0.0217, -0.2760,\n",
      "         -0.1374,  0.0180]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2057, -0.2169, -0.1202, -0.1367, -0.1297, -0.1764, -0.2756,  0.0659,\n",
      "         0.1241, -0.2031], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3046,  0.2104, -0.1273, -0.2131,  0.2745, -0.3051, -0.0776,  0.0997,\n",
      "         -0.1458,  0.0538],\n",
      "        [-0.1922, -0.0659, -0.1942, -0.1498,  0.2258,  0.0309, -0.2359,  0.0757,\n",
      "         -0.0637,  0.2616],\n",
      "        [ 0.1609, -0.0869, -0.1721, -0.2505,  0.2684, -0.2718,  0.1846,  0.1231,\n",
      "         -0.2976, -0.1628],\n",
      "        [-0.3112, -0.2346, -0.2763, -0.0315, -0.1602, -0.0729, -0.2051, -0.2751,\n",
      "          0.2031,  0.0551],\n",
      "        [-0.0782,  0.0084,  0.0724, -0.0857,  0.1319, -0.1139, -0.2603,  0.1336,\n",
      "          0.2207,  0.1591],\n",
      "        [-0.0995,  0.2685,  0.1448,  0.0445, -0.1821, -0.1157,  0.2048, -0.0757,\n",
      "          0.0043,  0.2685],\n",
      "        [-0.1348,  0.2288, -0.0973, -0.0015,  0.1221,  0.0078,  0.0417,  0.2495,\n",
      "         -0.1759, -0.2033],\n",
      "        [-0.0948, -0.2972,  0.0630,  0.2993, -0.1058, -0.2300, -0.2822,  0.1344,\n",
      "         -0.0026,  0.0454],\n",
      "        [-0.1454, -0.0066, -0.1433,  0.1991, -0.0202, -0.1045,  0.2825, -0.2434,\n",
      "         -0.0332, -0.0325],\n",
      "        [-0.2724,  0.2923, -0.3041, -0.2016,  0.1354,  0.2401, -0.2301,  0.1740,\n",
      "          0.1919,  0.1738]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.1133e-01,  3.1121e-02,  3.1224e-01,  1.0484e-01, -1.3572e-03,\n",
      "         6.7353e-06,  1.9083e-01, -2.0748e-01, -3.1228e-01, -3.1960e-02],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "'''\n",
    "model = models.resnet18(pretrained=False) # set model here\n",
    "in_ftr = model.fc.in_features\n",
    "out_ftr = n_classes\n",
    "model.fc = nn.Linear(in_ftr,out_ftr,bias=True)\n",
    "'''\n",
    "\n",
    "# redefining stuff for AdaSecant test runs\n",
    "X_train = torch.rand(256, 10)\n",
    "X_test = torch.rand(256, 10)\n",
    "y_train = torch.randint(10, (256,))\n",
    "y_test = torch.randint(10, (256,))\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "model = torch.nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10))\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "dataset_test = BasicDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check specs for GPU-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device name: NVIDIA GeForce 940MX\n",
      "cuda device id 0\n"
     ]
    }
   ],
   "source": [
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('cuda device name:', torch.cuda.get_device_name())\n",
    "print('cuda device id', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model and data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train.to(device)\n",
    "print('worked?', X_train.to(device).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing AdaSecant\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class AdaSecant(optim.Optimizer):\n",
    "    r\"\"\"Documentation\n",
    "    Basis copied from https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py.\n",
    "    Left out closure, momentum-related stuff, __setstate__ as it does not seem to be necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=None):\n",
    "        if lr is not None:\n",
    "            print('Warning: lr is not a parameter for AdaSecant. Your lr will be set to None')\n",
    "            lr = None\n",
    "        defaults = dict(lr=lr)\n",
    "        super().__init__(params, defaults)\n",
    "        # here we need to introduce some attribute to save params/gradients from old batch.\n",
    "        self.moving_average_of_g = None\n",
    "        self.delta = None\n",
    "        self.memory_size = None\n",
    "        self.gradients = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \"\"\"\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            # all parameters of a model seem to be contained within the same group\n",
    "            params_with_grad = []\n",
    "            d_p_list = []\n",
    "            \n",
    "            # ToDo: update old params/gradients\n",
    "\n",
    "            for p in group['params']:\n",
    "                # subgrouping of parameters for each layer, bias and weights separately (each tensor)\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    d_p_list.append(p.grad)\n",
    "                    state = self.state[p]\n",
    "\n",
    "            #adasecant(self, params_with_grad, d_p_list)\n",
    "            \n",
    "        return #loss\n",
    "    \n",
    "def adasecant(optimizer: AdaSecant, params: List[torch.Tensor], d_p_list: List[torch.Tensor]):\n",
    "    # d_p_list[i] corresponds to param[i]\n",
    "    for i, param in enumerate(params):\n",
    "        g = d_p_list[i]\n",
    "        correction_term = None # to be implemented\n",
    "        corrected_gradient = None # to be implemented\n",
    "        \n",
    "        \n",
    "    # update all attributes in optimizer\n",
    "    optimizer.gradients = g\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, batch_size=1000):\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        yhat = model.forward(batch['X'].float().to(device))\n",
    "        y = batch['y'].long().to(device)\n",
    "        batch_loss = f_loss(yhat, y)\n",
    "        loss += batch_loss.item() * len(batch['X'])\n",
    "        correct += (torch.argmax(yhat, dim=1) == y).float().sum().item()\n",
    "    accuracy = correct / len(dataset)\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def get_scheduler(optimizer, base_lr, max_lr, epochs_per_cycle, len_dataset, batch_size):\n",
    "    if epochs_per_cycle is None:\n",
    "        epochs_per_cycle = epochs\n",
    "    iterations_per_cycle = epochs_per_cycle * (len_dataset // batch_size)\n",
    "    return torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=iterations_per_cycle / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, validation_set, base_lr=0.01, max_lr=0.01, batch_size=64, epochs=1, \n",
    "                f_opt=optim.SGD, f_loss=F.cross_entropy, epochs_per_cycle=None):\n",
    "    \n",
    "    optimizer = f_opt(model.parameters(), lr=base_lr)\n",
    "    #scheduler = get_scheduler(optimizer, base_lr, max_lr, epochs_per_cycle, len(dataset), batch_size)\n",
    "    lr_history = []\n",
    "    validation_accuracy = []\n",
    "    epoch_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    # evaluate initial state of model\n",
    "    initial_training_loss, _ = evaluate_model(model, dataset)\n",
    "    epoch_losses.append(initial_training_loss)\n",
    "    validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracy.append(accuracy)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training and epoch loss logging\n",
    "        # drop last to avoid stochastic outliers in gradient update\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0 \n",
    "        for batch in data_loader:\n",
    "            model.zero_grad()\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "            batch_loss = f_loss(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item() * len(batch['X'])\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            #lr_history.append(scheduler.get_last_lr()[0])\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss / len(dataset)}') # - LR: {scheduler.get_last_lr()[0]}\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # calculate validation loss and accuracy\n",
    "        validation_loss, accuracy = evaluate_model(model, validation_set)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return (np.array(epoch_losses) / len(dataset), \n",
    "            np.array(validation_losses) / len(validation_set), \n",
    "            validation_accuracy, \n",
    "            lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: lr is not a parameter for AdaSecant. Your lr will be set to None\n",
      "new group\n",
      "new p\n",
      "Parameter containing:\n",
      "tensor([[-0.0307,  0.1358, -0.0368, -0.0422,  0.3025, -0.1505,  0.0907,  0.2641,\n",
      "          0.1772, -0.0982],\n",
      "        [-0.0499, -0.2237,  0.0668,  0.0828,  0.2420, -0.2718,  0.0835,  0.2897,\n",
      "          0.1669,  0.2974],\n",
      "        [-0.2263, -0.3051,  0.0991, -0.2579,  0.0698, -0.0645,  0.1596, -0.2823,\n",
      "          0.2093,  0.3030],\n",
      "        [ 0.1678, -0.2800, -0.1675, -0.0903, -0.0736,  0.2535, -0.2156, -0.0693,\n",
      "          0.2214, -0.0740],\n",
      "        [ 0.0404, -0.0801, -0.0873, -0.0432, -0.2931, -0.2614, -0.2044,  0.3128,\n",
      "          0.3118,  0.2880],\n",
      "        [-0.0824,  0.0239,  0.3014, -0.0298, -0.3021, -0.0788, -0.0471, -0.1353,\n",
      "         -0.0611, -0.0636],\n",
      "        [-0.0420, -0.1355, -0.0762,  0.1873,  0.2776,  0.3024,  0.1973, -0.2825,\n",
      "          0.3017, -0.2270],\n",
      "        [ 0.2911,  0.1270, -0.2400,  0.0685, -0.1103, -0.2818,  0.1577, -0.0409,\n",
      "          0.2809,  0.2704],\n",
      "        [ 0.2723, -0.1110, -0.0573, -0.1249,  0.0560, -0.3064,  0.0026, -0.1962,\n",
      "          0.0152,  0.1414],\n",
      "        [ 0.1333,  0.0979,  0.2745,  0.1944, -0.3043,  0.2162,  0.0217, -0.2760,\n",
      "         -0.1374,  0.0180]], device='cuda:0', requires_grad=True)\n",
      "new p\n",
      "Parameter containing:\n",
      "tensor([ 0.2057, -0.2169, -0.1202, -0.1367, -0.1297, -0.1764, -0.2756,  0.0659,\n",
      "         0.1241, -0.2031], device='cuda:0', requires_grad=True)\n",
      "new p\n",
      "Parameter containing:\n",
      "tensor([[-0.3046,  0.2104, -0.1273, -0.2131,  0.2745, -0.3051, -0.0776,  0.0997,\n",
      "         -0.1458,  0.0538],\n",
      "        [-0.1922, -0.0659, -0.1942, -0.1498,  0.2258,  0.0309, -0.2359,  0.0757,\n",
      "         -0.0637,  0.2616],\n",
      "        [ 0.1609, -0.0869, -0.1721, -0.2505,  0.2684, -0.2718,  0.1846,  0.1231,\n",
      "         -0.2976, -0.1628],\n",
      "        [-0.3112, -0.2346, -0.2763, -0.0315, -0.1602, -0.0729, -0.2051, -0.2751,\n",
      "          0.2031,  0.0551],\n",
      "        [-0.0782,  0.0084,  0.0724, -0.0857,  0.1319, -0.1139, -0.2603,  0.1336,\n",
      "          0.2207,  0.1591],\n",
      "        [-0.0995,  0.2685,  0.1448,  0.0445, -0.1821, -0.1157,  0.2048, -0.0757,\n",
      "          0.0043,  0.2685],\n",
      "        [-0.1348,  0.2288, -0.0973, -0.0015,  0.1221,  0.0078,  0.0417,  0.2495,\n",
      "         -0.1759, -0.2033],\n",
      "        [-0.0948, -0.2972,  0.0630,  0.2993, -0.1058, -0.2300, -0.2822,  0.1344,\n",
      "         -0.0026,  0.0454],\n",
      "        [-0.1454, -0.0066, -0.1433,  0.1991, -0.0202, -0.1045,  0.2825, -0.2434,\n",
      "         -0.0332, -0.0325],\n",
      "        [-0.2724,  0.2923, -0.3041, -0.2016,  0.1354,  0.2401, -0.2301,  0.1740,\n",
      "          0.1919,  0.1738]], device='cuda:0', requires_grad=True)\n",
      "new p\n",
      "Parameter containing:\n",
      "tensor([-3.1133e-01,  3.1121e-02,  3.1224e-01,  1.0484e-01, -1.3572e-03,\n",
      "         6.7353e-06,  1.9083e-01, -2.0748e-01, -3.1228e-01, -3.1960e-02],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 1/1 - Loss: 2.34623646736145\n"
     ]
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "max_lr = 0.1\n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "f_opt = AdaSecant\n",
    "f_loss = F.cross_entropy\n",
    "cycle = epochs\n",
    "\n",
    "training_loss, validation_loss, validation_accuracy, lr_history = train_model(model.to(device),\n",
    "                                                                              dataset_train,\n",
    "                                                                              dataset_test,\n",
    "                                                                              base_lr,\n",
    "                                                                              max_lr,\n",
    "                                                                              batch_size,\n",
    "                                                                              epochs,\n",
    "                                                                              f_opt,\n",
    "                                                                              f_loss,\n",
    "                                                                              cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x209655fbf70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label='training loss')\n",
    "plt.plot(validation_loss, label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Cross Entropy Loss')\n",
    "#plt.ylim(0.0, 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2090f1dbaf0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1015625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_accuracy)\n",
    "print(max(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1045e0c59eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from google.colab import files\n",
    "\n",
    "with open('train_loss', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(training_loss)\n",
    "\n",
    "with open('val_loss', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_loss)\n",
    "\n",
    "with open('val_accuracy', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(validation_accuracy)\n",
    "    \n",
    "with open('lr_history', 'w') as f: \n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(lr_history)\n",
    "\n",
    "files.download('train_loss')\n",
    "files.download('val_loss')\n",
    "files.download('val_accuracy')\n",
    "files.download('lr_history')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
